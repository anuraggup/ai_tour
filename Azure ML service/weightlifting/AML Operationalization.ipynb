{"cells":[{"cell_type":"code","source":["import azureml.core\n\nprint(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">You are currently using version 1.0.18 of the Azure ML SDK\n</div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["##### Create Azure ML Workspace, if it doesn't exist"],"metadata":{}},{"cell_type":"code","source":["from azureml.core import Workspace\n\nsubscription_id = \"4dd7cdaa-1664-46be-b521-237c98ccf3f6\"\n\nws = Workspace.create(name=\"ML-Service-Workspace\",\n                      subscription_id=subscription_id,    \n                      resource_group=\"ML-Service-RG\",\n                      create_resource_group=True,\n                      location=\"eastus\",\n                      exist_ok=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["##### Write workspace configuration file to local FS"],"metadata":{}},{"cell_type":"code","source":["ws.write_config()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote the config file config.json to: /databricks/driver/aml_config/config.json\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["##### Copy workspace configuration file to DBFS, to persist it"],"metadata":{}},{"cell_type":"code","source":["%sh cp /databricks/driver/aml_config/config.json /dbfs/tmp"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["##### Copy serialized model file from DBFS to local FS"],"metadata":{}},{"cell_type":"code","source":["#NOTE: Need to copy model from DBFS to local FS, as Azure ML service deployment always gets the model from the current working dir\nimport os\n\nbase_path = \"/tmp/rf_model/\"\nmodel_name = \"rf_model\"\n\nmodel_local = \"file:\" + os.getcwd() + \"/\" + model_name\ndbutils.fs.cp(base_path, model_local, True)\n\nlocal_path = os.getcwd() + \"/\" + model_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">copy model from dbfs to local\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["%sh ls -la /databricks/driver/rf_model/rf_model.mllib"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total 16\ndrwxr-xr-x 4 root root 4096 Mar 20 00:47 .\ndrwxr-xr-x 3 root root 4096 Mar 20 00:47 ..\ndrwxr-xr-x 2 root root 4096 Mar 20 00:47 metadata\ndrwxr-xr-x 5 root root 4096 Mar 20 00:47 stages\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["##### Register the model on Azure ML service"],"metadata":{}},{"cell_type":"code","source":["#Register the model\nfrom azureml.core.model import Model\n\nmymodel = Model.register(model_path = model_name + \"/rf_model.mllib\", # local path where the model file was copied to\n                         model_name = model_name, # this is the name to be used to register the model on Azure ML service\n                         description = \"MLlib Randomforest Model\",\n                         workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model rf_model\nrf_model MLlib Randomforest Model 15\n</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["##### Create a model scoring script and save it to local FS"],"metadata":{}},{"cell_type":"code","source":["score_sparkml = \"\"\"\n\nimport json\nimport pickle\nimport pyspark\nfrom azureml.core.model import Model\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.feature import IndexToString\n\ndef init():\n    # One-time initialization of PySpark and predictive model\n\n    global trainedModel\n    global spark\n\n    spark = pyspark.sql.SparkSession.builder.appName(\"MLlib Randomforest Model Operationalization\").getOrCreate()\n    model_name = \"{model_name}\" #interpolated\n    model_path = Model.get_model_path(model_name)\n    trainedModel = PipelineModel.load(model_path)\n    \ndef run(input_json):\n    if isinstance(trainedModel, Exception):\n        return json.dumps({{\"trainedModel\":str(trainedModel)}})\n      \n    try:\n        sc = spark.sparkContext\n        input_list = [json.loads(input_json)]\n        input_rdd = sc.parallelize(input_list)\n        input_df = spark.read.json(input_rdd)\n    \n        # Compute prediction\n        prediction = trainedModel.transform(input_df)\n        idx_to_string = IndexToString(inputCol=\"prediction\", outputCol=\"classe_predicted\", labels=trainedModel.stages[-3].labels)\n        prediction = idx_to_string.transform(prediction)\n        \n        #result = prediction.first().prediction\n        predictions = prediction.collect()\n\n        #Get each scored result\n        preds = [str(x[\"classe_predicted\"]) for x in predictions]\n        result = \",\".join(preds)\n        # you can return any data type as long as it is JSON-serializable\n        return json.dumps({{\"result\":result}})        \n    except Exception as e:\n        result = str(e)\n        return json.dumps({{\"error\":result}})\n    \n\"\"\".format(model_name=model_name)\n\nexec(score_sparkml)\n\nwith open(\"score_sparkml.py\", \"w\") as file:\n    file.write(score_sparkml)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["##### Create a deployment configuration file, optionally listing any dependent packages"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies \n\nmyacienv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas']) #showing how to add libs as an example - not needed for this model.\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(myacienv.serialize_to_string())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["##### Create deployment configuration"],"metadata":{}},{"cell_type":"code","source":["#Deployment configuration\nfrom azureml.core.webservice import AciWebservice, Webservice\n\nmyaci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 2, \n    memory_gb = 2, \n    tags = {'name':'Databricks Azure ML ACI'}, \n    description = 'ACI to serve ADB Randomforest model.')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["##### Create an image to host the model scoring script and deploy the web service"],"metadata":{}},{"cell_type":"code","source":["#This will take 10-15 minutes to finish\n\nservice_name = \"aciadbws\"\nruntime = \"spark-py\" \ndriver_file = \"score_sparkml.py\"\nmy_conda_file = \"mydeployenv.yml\"\n\n# image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file,\n                                                    runtime = runtime,\n                                                    conda_file = my_conda_file)\n\n# Webservice creation\nmyservice = Webservice.deploy_from_model(workspace=ws,\n                                         name=service_name,\n                                         deployment_config = myaci_config,\n                                         models = [mymodel],\n                                         image_config = myimage_config)\n\nmyservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating image\nImage creation operation finished for image aciadbws:12, operation &quot;Succeeded&quot;\nCreating service\nRunning......................................................\nSucceededACI service creation operation finished, operation &quot;Succeeded&quot;\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["print(myservice.state)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Healthy\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["print(myservice.get_logs())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2019-03-20 01:35:01,050 CRIT Supervisor running as root (no user in config file)\n2019-03-20 01:35:01,052 INFO supervisord started with pid 1\n2019-03-20 01:35:02,054 INFO spawned: &apos;rsyslog&apos; with pid 9\n2019-03-20 01:35:02,056 INFO spawned: &apos;program_exit&apos; with pid 10\n2019-03-20 01:35:02,057 INFO spawned: &apos;nginx&apos; with pid 11\n2019-03-20 01:35:02,058 INFO spawned: &apos;iot&apos; with pid 12\n2019-03-20 01:35:02,060 INFO spawned: &apos;gunicorn&apos; with pid 13\n2019-03-20 01:35:02,080 INFO success: iot entered RUNNING state, process has stayed up for &gt; than 0 seconds (startsecs)\n2019-03-20 01:35:02,145 INFO exited: iot (exit status 1; expected)\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:02.488453Z&quot;, &quot;message&quot;: &quot;Starting gunicorn 19.6.0&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Starting gunicorn %s&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:02.489105Z&quot;, &quot;message&quot;: &quot;Listening at: http://127.0.0.1:9090 (13)&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Listening at: %s (%s)&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:02.489364Z&quot;, &quot;message&quot;: &quot;Using worker: sync&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Using worker: %s&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:02.489933Z&quot;, &quot;message&quot;: &quot;worker timeout is set to 300&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:02.490786Z&quot;, &quot;message&quot;: &quot;Booting worker with pid: 35&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Booting worker with pid: %s&quot;, &quot;stack_info&quot;: null}\n2019-03-20 01:35:03,492 INFO success: rsyslog entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2019-03-20 01:35:03,493 INFO success: program_exit entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\nIvy Default Cache set to: /root/.ivy2/cache\nThe jars for the packages stored in: /root/.ivy2/jars\n:: loading settings :: url = jar:file:/home/mmlspark/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\ncom.microsoft.ml.spark#mmlspark_2.11 added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-263675ef-0995-449d-bbf9-67147be79fb6;1.0\n\tconfs: [default]\n\tfound com.microsoft.ml.spark#mmlspark_2.11;0.15 in spark-list\n\tfound io.spray#spray-json_2.11;1.3.2 in central\n\tfound com.microsoft.cntk#cntk;2.4 in central\n\tfound org.openpnp#opencv;3.2.0-1 in central\n\tfound com.jcraft#jsch;0.1.54 in central\n\tfound org.apache.httpcomponents#httpclient;4.5.6 in central\n\tfound org.apache.httpcomponents#httpcore;4.4.10 in central\n\tfound commons-logging#commons-logging;1.2 in central\n\tfound commons-codec#commons-codec;1.10 in central\n\tfound com.microsoft.ml.lightgbm#lightgbmlib;2.1.250 in central\n:: resolution report :: resolve 477ms :: artifacts dl 53ms\n\t:: modules in use:\n\tcom.jcraft#jsch;0.1.54 from central in [default]\n\tcom.microsoft.cntk#cntk;2.4 from central in [default]\n\tcom.microsoft.ml.lightgbm#lightgbmlib;2.1.250 from central in [default]\n\tcom.microsoft.ml.spark#mmlspark_2.11;0.15 from spark-list in [default]\n\tcommons-codec#commons-codec;1.10 from central in [default]\n\tcommons-logging#commons-logging;1.2 from central in [default]\n\tio.spray#spray-json_2.11;1.3.2 from central in [default]\n\torg.apache.httpcomponents#httpclient;4.5.6 from central in [default]\n\torg.apache.httpcomponents#httpcore;4.4.10 from central in [default]\n\torg.openpnp#opencv;3.2.0-1 from central in [default]\n\t---------------------------------------------------------------------\n                  |            modules            ||   artifacts   |\n       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n      default     |   10  |   0   |   0   |   0   ||   10  |   0   |\n\t---------------------------------------------------------------------\n\n:: problems summary ::\n:::: ERRORS\n\tunknown resolver repo-1\n\n\tunknown resolver repo-1\n\n\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n:: retrieving :: org.apache.spark#spark-submit-parent-263675ef-0995-449d-bbf9-67147be79fb6\n\tconfs: [default]\n\t0 artifacts copied, 10 already retrieved (0kB/9ms)\n2019-03-20 01:35:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to &quot;WARN&quot;.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n2019-03-20 01:35:07,599 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 5 seconds (startsecs)\nInitializing logger\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:09.505452Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Starting up app insights client\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:09.505641Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Starting up request id generator\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:09.505725Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Starting up app insight hooks\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:09.505829Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Invoking user&apos;s init function\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n2019-03-20 01:35:09,510 | azureml.core.run | DEBUG | Could not load run context Failed to load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run., switching offline: False\n2019-03-20 01:35:09,510 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n2019-03-20 01:35:09,510 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n2019-03-20 01:35:09,510 | azureml.core.model | DEBUG | version is None. Latest version is 15\n2019-03-20 01:35:09,510 | azureml.core.model | DEBUG | Found model path at azureml-models/rf_model/15/rf_model.mllib\n\r[Stage 0:&gt;                                                          (0 + 1) / 1]2019-03-20 01:35:22,532 INFO success: gunicorn entered RUNNING state, process has stayed up for &gt; than 20 seconds (startsecs)\n\r                                                                                \r\r[Stage 5:&gt;                                                          (0 + 1) / 1]\r                                                                                \r\r[Stage 14:&gt;                                                         (0 + 1) / 1]\r[Stage 15:&gt;                                                         (0 + 1) / 1]\r[Stage 16:&gt;                                                         (0 + 1) / 1]\r                                                                                \r{&quot;timestamp&quot;: &quot;2019-03-20T01:35:38.578023Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Users&apos;s init has completed successfully\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:38.579299Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Scoring timeout setting is not found. Use default timeout: 3600000 ms\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:38.581461Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [20/Mar/2019:01:35:38 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:38.582431Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [20/Mar/2019:01:35:38 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:45.747860Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [20/Mar/2019:01:35:45 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-03-20T01:35:48.287987Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [20/Mar/2019:01:35:48 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-2086907bdabd4da2bade8b2c57ad64b6-8efc4719bdd604d136c157&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n\n</div>"]}}],"execution_count":22}],"metadata":{"name":"AML Operationalization","notebookId":2749774669492328},"nbformat":4,"nbformat_minor":0}
