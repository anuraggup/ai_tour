{"cells":[{"cell_type":"code","source":["import azureml.core\n\nprint(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">You are currently using version 1.0.23 of the Azure ML SDK\n</div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["##### Read the workspace configuration file and create a reference object to the workspace"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.workspace import Workspace\n\nws = Workspace.from_config(\"/dbfs/tmp/config.json\")\nprint(\"Workspace name: \" + ws.name, \n      \"Azure region: \" + ws.location,\n      \"Resource group: \" + ws.resource_group, sep = \"\\n\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Found the config file in: /dbfs/tmp/config.json\nWorkspace name: ML-Service-Workspace\nAzure region: eastus\nResource group: ML-Service-RG\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["##### Copy serialized model file from DBFS to local FS"],"metadata":{}},{"cell_type":"code","source":["#NOTE: Need to copy model from DBFS to local FS, as Azure ML service deployment always gets the model from the current working dir\nimport os\n\nbase_path = \"/tmp/rf_model/\"\nmodel_name = \"rf_model\"\n\nmodel_local = \"file:\" + os.getcwd() + \"/\" + model_name\ndbutils.fs.cp(base_path, model_local, True)\n\nlocal_path = os.getcwd() + \"/\" + model_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["%sh ls -la /databricks/driver/rf_model/rf_model.mllib"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total 16\ndrwxr-xr-x 4 root root 4096 Apr 19 12:49 .\ndrwxr-xr-x 3 root root 4096 Apr 19 12:49 ..\ndrwxr-xr-x 2 root root 4096 Apr 19 12:49 metadata\ndrwxr-xr-x 5 root root 4096 Apr 19 12:49 stages\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["##### Register the model on Azure ML service"],"metadata":{}},{"cell_type":"code","source":["#Register the model\nfrom azureml.core.model import Model\n\nmymodel = Model.register(model_path = model_name + \"/rf_model.mllib\", # local path where the model file was copied to\n                         model_name = model_name, # this is the name to be used to register the model on Azure ML service\n                         description = \"MLlib Randomforest Model\",\n                         workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model rf_model\nrf_model MLlib Randomforest Model 16\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["##### Create a model scoring script and save it to local FS"],"metadata":{}},{"cell_type":"code","source":["score_sparkml = \"\"\"\n\nimport json\nimport pickle\nimport pyspark\nfrom azureml.core.model import Model\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.feature import IndexToString\n\ndef init():\n    # One-time initialization of PySpark and predictive model\n\n    global trainedModel\n    global spark\n\n    spark = pyspark.sql.SparkSession.builder.appName(\"MLlib Randomforest Model Operationalization\").getOrCreate()\n    model_name = \"{model_name}\" #interpolated\n    model_path = Model.get_model_path(model_name)\n    trainedModel = PipelineModel.load(model_path)\n    \ndef run(input_json):\n    if isinstance(trainedModel, Exception):\n        return json.dumps({{\"trainedModel\":str(trainedModel)}})\n      \n    try:\n        sc = spark.sparkContext\n        input_list = [json.loads(input_json)]\n        input_rdd = sc.parallelize(input_list)\n        input_df = spark.read.json(input_rdd)\n    \n        # Compute prediction\n        prediction = trainedModel.transform(input_df)\n        idx_to_string = IndexToString(inputCol=\"prediction\", outputCol=\"classe_predicted\", labels=trainedModel.stages[-3].labels)\n        prediction = idx_to_string.transform(prediction)\n        \n        #result = prediction.first().prediction\n        predictions = prediction.collect()\n\n        #Get each scored result\n        preds = [str(x[\"classe_predicted\"]) for x in predictions]\n        result = \",\".join(preds)\n        # you can return any data type as long as it is JSON-serializable\n        return json.dumps({{\"result\":result}})        \n    except Exception as e:\n        result = str(e)\n        return json.dumps({{\"error\":result}})\n    \n\"\"\".format(model_name=model_name)\n\nexec(score_sparkml)\n\nwith open(\"score_sparkml.py\", \"w\") as file:\n    file.write(score_sparkml)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["##### Create a deployment configuration file, optionally listing any dependent packages"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies \n\nmyacienv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas']) #showing how to add libs as an example - not needed for this model.\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(myacienv.serialize_to_string())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["##### Create deployment configuration"],"metadata":{}},{"cell_type":"code","source":["#Deployment configuration\nfrom azureml.core.webservice import AciWebservice, Webservice\n\nmyaci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 2, \n    memory_gb = 2, \n    tags = {'name':'Databricks Azure ML ACI'}, \n    description = 'ACI to serve ADB Randomforest model.')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["##### Create an image to host the model scoring script and deploy the web service"],"metadata":{}},{"cell_type":"code","source":["#This will take 10-15 minutes to finish\n\nservice_name = \"aciadbws\"\nruntime = \"spark-py\" \ndriver_file = \"score_sparkml.py\"\nmy_conda_file = \"mydeployenv.yml\"\n\n# image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file,\n                                                    runtime = runtime,\n                                                    conda_file = my_conda_file)\n\n# Webservice creation\nmyservice = Webservice.deploy_from_model(workspace=ws,\n                                         name=service_name,\n                                         deployment_config = myaci_config,\n                                         models = [mymodel],\n                                         image_config = myimage_config)\n\nmyservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating image\nImage creation operation finished for image aciadbws:13, operation &quot;Succeeded&quot;\nCreating service\nRunning...................................................................\nSucceededACI service creation operation finished, operation &quot;Succeeded&quot;\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["print(myservice.state)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Healthy\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["print(myservice.get_logs())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2019-04-19T13:00:17,481872480+00:00 - gunicorn/run \n2019-04-19T13:00:17,481930882+00:00 - iot-server/run \n2019-04-19T13:00:17,482257694+00:00 - rsyslog/run \n2019-04-19T13:00:17,482871016+00:00 - nginx/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2019-04-19T13:00:17,591309859+00:00 - iot-server/finish 1 0\n2019-04-19T13:00:17,592282094+00:00 - Exit code 1 is normal. Not restarting iot-server.\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:18.773435Z&quot;, &quot;message&quot;: &quot;Starting gunicorn 19.6.0&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Starting gunicorn %s&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:18.774210Z&quot;, &quot;message&quot;: &quot;Listening at: http://127.0.0.1:9090 (12)&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Listening at: %s (%s)&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:18.774319Z&quot;, &quot;message&quot;: &quot;Using worker: sync&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Using worker: %s&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:18.774925Z&quot;, &quot;message&quot;: &quot;worker timeout is set to 300&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:18.776381Z&quot;, &quot;message&quot;: &quot;Booting worker with pid: 51&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.error&quot;, &quot;msg&quot;: &quot;Booting worker with pid: %s&quot;, &quot;stack_info&quot;: null}\nIvy Default Cache set to: /root/.ivy2/cache\nThe jars for the packages stored in: /root/.ivy2/jars\n:: loading settings :: url = jar:file:/home/mmlspark/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\ncom.microsoft.ml.spark#mmlspark_2.11 added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-17cad6b6-8863-4b4d-a429-65570a978795;1.0\n\tconfs: [default]\n\tfound com.microsoft.ml.spark#mmlspark_2.11;0.15 in spark-list\n\tfound io.spray#spray-json_2.11;1.3.2 in central\n\tfound com.microsoft.cntk#cntk;2.4 in central\n\tfound org.openpnp#opencv;3.2.0-1 in central\n\tfound com.jcraft#jsch;0.1.54 in central\n\tfound org.apache.httpcomponents#httpclient;4.5.6 in central\n\tfound org.apache.httpcomponents#httpcore;4.4.10 in central\n\tfound commons-logging#commons-logging;1.2 in central\n\tfound commons-codec#commons-codec;1.10 in central\n\tfound com.microsoft.ml.lightgbm#lightgbmlib;2.1.250 in central\n:: resolution report :: resolve 610ms :: artifacts dl 10ms\n\t:: modules in use:\n\tcom.jcraft#jsch;0.1.54 from central in [default]\n\tcom.microsoft.cntk#cntk;2.4 from central in [default]\n\tcom.microsoft.ml.lightgbm#lightgbmlib;2.1.250 from central in [default]\n\tcom.microsoft.ml.spark#mmlspark_2.11;0.15 from spark-list in [default]\n\tcommons-codec#commons-codec;1.10 from central in [default]\n\tcommons-logging#commons-logging;1.2 from central in [default]\n\tio.spray#spray-json_2.11;1.3.2 from central in [default]\n\torg.apache.httpcomponents#httpclient;4.5.6 from central in [default]\n\torg.apache.httpcomponents#httpcore;4.4.10 from central in [default]\n\torg.openpnp#opencv;3.2.0-1 from central in [default]\n\t---------------------------------------------------------------------\n                  |            modules            ||   artifacts   |\n       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n      default     |   10  |   0   |   0   |   0   ||   10  |   0   |\n\t---------------------------------------------------------------------\n\n:: problems summary ::\n:::: ERRORS\n\tunknown resolver repo-1\n\n\tunknown resolver repo-1\n\n\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n:: retrieving :: org.apache.spark#spark-submit-parent-17cad6b6-8863-4b4d-a429-65570a978795\n\tconfs: [default]\n\t0 artifacts copied, 10 already retrieved (0kB/9ms)\n2019-04-19 13:00:21 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to &quot;WARN&quot;.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\nInitialized PySpark session.\nInitializing logger\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:27.052976Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Starting up app insights client\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:27.053196Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Starting up request id generator\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:27.053298Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Starting up app insight hooks\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:27.053391Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Invoking user&apos;s init function\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n2019-04-19 13:00:27,061 | azureml.core.run | DEBUG | Could not load run context Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run., switching offline: False\n2019-04-19 13:00:27,061 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n2019-04-19 13:00:27,062 | azureml.core.model | DEBUG | RunEnvironmentException: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n2019-04-19 13:00:27,062 | azureml.core.model | DEBUG | version is None. Latest version is 16\n2019-04-19 13:00:27,062 | azureml.core.model | DEBUG | Found model path at azureml-models/rf_model/16/rf_model.mllib\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:56.913554Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Users&apos;s init has completed successfully\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:56.914888Z&quot;, &quot;message&quot;: &quot;{\\&quot;requestId\\&quot;: \\&quot;00000000-0000-0000-0000-000000000000\\&quot;, \\&quot;message\\&quot;: \\&quot;Scoring timeout setting is not found. Use default timeout: 3600000 ms\\&quot;, \\&quot;apiName\\&quot;: \\&quot;\\&quot;}&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/var/azureml-app/aml_logger.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;root&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:56.917694Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [19/Apr/2019:13:00:56 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:56.918535Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [19/Apr/2019:13:00:56 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n{&quot;timestamp&quot;: &quot;2019-04-19T13:00:57.735608Z&quot;, &quot;message&quot;: &quot;127.0.0.1 - - [19/Apr/2019:13:00:57 +0000] \\&quot;GET / HTTP/1.0\\&quot; 200 7 \\&quot;-\\&quot; \\&quot;Go-http-client/1.1\\&quot;&quot;, &quot;host&quot;: &quot;wk-caas-788a4d908f1542c5a1b02b2f290c532d-d653029852df100957b508&quot;, &quot;path&quot;: &quot;/home/mmlspark/lib/conda/lib/python3.6/site-packages/gunicorn/glogging.py&quot;, &quot;tags&quot;: &quot;%(module)s, %(asctime)s, %(levelname)s, %(message)s&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;gunicorn.access&quot;, &quot;stack_info&quot;: null}\n\n</div>"]}}],"execution_count":18}],"metadata":{"name":"AML Operationalization","notebookId":2749774669492328},"nbformat":4,"nbformat_minor":0}
