{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Training\n",
    "### Train the PyTorch Deep Learning regression model with Azure ML service on a remote Azure ML Compute resource\n",
    "\n",
    "#### <font color='red'> Before you begin: please download the training dataset from Kaggle and save it into the \"data\" folder as \"train.csv\". You will need to login into Kaggle to be able to download the dataset. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup diagnostics collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\AI+ Tour Tutorials\\Azure ML service\\housing\\AzureML\\aml_config\\config.json\n",
      "Workspace name: ML-Service-Workspace\n",
      "Azure region: eastus\n",
      "Resource group: ML-Service-RG\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace name: \" + ws.name, \n",
    "      \"Azure region: \" + ws.location, \n",
    "      \"Resource group: \" + ws.resource_group, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach your compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-02-15T13:47:12.310000+00:00', 'creationTime': '2019-02-15T13:47:08.984315+00:00', 'currentNodeCount': 0, 'errors': None, 'modifiedTime': '2019-02-15T13:47:26.304081+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 0, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "cluster_name = \"gpucluster\"\n",
    "compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "\n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the training script folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = \"./script\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Experiment in your Workspace to track the training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = \"pytorch-dl-regression\"\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob mlservicstoragevqkhmalr azureml-blobstore-03a77933-b9d0-4918-bd23-4f23d00afafb\n",
      "Uploading ../data\\train.csv\n",
      "Uploaded ../data\\train.csv, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_e2775e6b2b5740878e5a2b7612f6803f"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload(src_dir=\"../data\", target_path=\"pytorch-dl-regression\", overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Run Configuration or Estimator, which allows you to submit training jobs to your target compute environment. Here we create an Estimator, which is specific for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    \"--data-folder\": ds.as_mount(),\n",
    "    \"--num_hidden_layers\": 1,\n",
    "    \"--hidden_layer_size\": 256,\n",
    "    \"--dropout_rate\": 0.1,\n",
    "    \"--learning_rate\": 0.005\n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=script_folder,\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script=\"train_model.py\",\n",
    "                    use_gpu=True,\n",
    "                    conda_packages=[\"scikit-learn\", \"pandas\"]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit your trainig job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: pytorch-dl-regression,\n",
      "Id: pytorch-dl-regression_1550239454_4cf766ba,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Starting)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get more details of your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'pytorch-dl-regression_1550239454_4cf766ba', 'target': 'gpucluster', 'status': 'Starting', 'properties': {'azureml.runsource': 'experiment', 'ContentSnapshotId': 'd929bd20-3ecf-4ecd-b161-91b249ccecd2'}, 'runDefinition': {'Script': 'train_model.py', 'Arguments': ['--data-folder', '$AZUREML_DATAREFERENCE_workspaceblobstore', '--num_hidden_layers', '1', '--hidden_layer_size', '256', '--dropout_rate', '0.1', '--learning_rate', '0.005'], 'SourceDirectoryDataStore': None, 'Framework': 0, 'Communicator': 0, 'Target': 'gpucluster', 'DataReferences': {'workspaceblobstore': {'DataStoreName': 'workspaceblobstore', 'Mode': 'Mount', 'PathOnDataStore': None, 'PathOnCompute': None, 'Overwrite': False}}, 'JobName': None, 'AutoPrepareEnvironment': True, 'MaxRunDurationSeconds': None, 'NodeCount': 1, 'Environment': {'Python': {'InterpreterPath': 'python', 'UserManagedDependencies': False, 'CondaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'torch==1.0.0', 'torchvision==0.2.1']}, 'scikit-learn', 'pandas']}}, 'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'NCCL_SOCKET_IFNAME': '^docker0'}, 'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1', 'Enabled': True, 'SharedVolumes': True, 'Preparation': None, 'GpuSupport': True, 'ShmSize': '1g', 'Arguments': [], 'BaseImageRegistry': {'Address': None, 'Username': None, 'Password': None}}, 'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'], 'Packages': [{'Group': 'com.microsoft.ml.spark', 'Artifact': 'mmlspark_2.11', 'Version': '0.12'}], 'PrecachePackages': True}}, 'History': {'OutputCollection': True}, 'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'BatchAi': {'NodeCount': 0}, 'AmlCompute': {'Name': None, 'VmSize': None, 'VmPriority': None, 'RetainCluster': False, 'ClusterMaxNodeCount': 1}, 'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1}, 'Mpi': {'ProcessCountPerNode': 1}, 'Hdi': {'YarnDeployMode': 2}, 'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5}, 'ExposedPorts': None, 'PrepareEnvironment': None}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlservicstoragevqkhmalr.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-dl-regression_1550239454_4cf766ba/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=fwQI3j2EUNqikuZgQFetKc9stRkIgvWAikk80ZP6lKU%3D&st=2019-02-15T13%3A54%3A22Z&se=2019-02-15T22%3A04%3A22Z&sp=r'}}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor your job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fef94f64fd44b3a8062b736266f4ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you need to cancel your job while still running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.cancel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azure_automl)",
   "language": "python",
   "name": "azure_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
