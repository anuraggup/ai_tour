{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices Prediction\n",
    "\n",
    "### In this tutorial we will prepare a dataset with houses characteristics and selling prices and train a regression model for sales price prediction.\n",
    "\n",
    "#### The dataset to be used is the [Ames Housing Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) from Kaggle, which has variables describing (almost) every aspect of residential homes in Ames, Iowa.\n",
    "\n",
    "#### Usually in a problem like this, one would explore the data and apply a fair amount of feature engineering to construct a training dataset for some more traditional multivariate regression algorithm. But here we will use a different approach, based on a Deep Neural Network that tries to learn good feature representations while being trained for the regression problem. We call this an end-to-end approach.\n",
    "\n",
    "#### For that, we are going to apply a technique known as [Deep Learning for Tabular Data](https://www.fast.ai/2018/04/29/categorical-embeddings/), also known as \"Structured Deep Learning\". The main idea here is to represent categorical variables in a (dense) [embedding space](https://en.wikipedia.org/wiki/Embedding), instead of the usual [One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot). This embedding space is usually parameterized by a weight matrix, which in our case will be learned end-to-end with the regression problem.\n",
    "\n",
    "#### In a Deep Learning setup, this allows a model to learn useful concepts and relations between features. For a toy example, suppose you have a variable representing day-of-week.\n",
    "\n",
    "#### For the values \"Sunday\", \"Monday\", and \"Tuesday\" there would be an one-hot-encodding representation like this:\n",
    "| day     | b1 | b2 | b3 | b4 | b5 | b6 | b7 |\n",
    "|---------|----|----|----|----|----|----|----|\n",
    "| Sunday  | 1  | 0  | 0  | 0  | 0  | 0  | 0  |\n",
    "| Monday  | 0  | 1  | 0  | 0  | 0  | 0  | 0  |\n",
    "| Tuesday | 0  | 0  | 1  | 0  | 0  | 0  | 0  |\n",
    "\n",
    "#### Now suppose you train an embedding layer of size 3 for this variable, end-to-end. Your model could then learn something like this:\n",
    "| day     | e1  | e2  | e3  | e4  |\n",
    "|---------|-----|-----|-----|-----|\n",
    "| Sunday  | 0.8 | 0.2 | 0.1 | 0.1 |\n",
    "| Monday  | 0.1 | 0.2 | 0.9 | 0.9 |\n",
    "| Tuesday | 0.2 | 0.1 | 0.9 | 0.8 |\n",
    "\n",
    "#### Notice that while the one-hot encoding representation does not capture anything interesting about the data, the learned embeddings might capture a useful concept like being a weekday or not. In the example above, we see that the vectors representing Monday and Tuesday are closer to each other than the vector representing Sunday, and the first dimension of the embedding vector could represent that concept of a weekday.\n",
    "\n",
    "#### We will begin by analyzing the dataset and performing a very basic preparation, like dealing with missing values and correcting data types for the variables. We then will construct and train a deep neural network for regression, using the [PyTorch](https://pytorch.org/) framework, that learns to predict house prices.\n",
    "\n",
    "#### The purpose of this notebook is to explain the concepts described here in a more friendly manner. We will then perform the same training process defined here in the cloud, in a scalable manner using a cluster of GPUs and show the power of the Hyperdrive functionality of Azure Machine Learning service for hyperparameter tuning.\n",
    "\n",
    "#### <font color='red'> Before you begin: please download the training dataset from Kaggle and save it into the \"data\" folder as \"train.csv\". You will need to login into Kaggle to be able to download the dataset. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We begin by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then load the dataset into a Pandas data frame, visualize the first 10 rows, and print the total number of rows and columns. We notice that this dataset has 1460 rows and 81 columns. Our response variable is the column named \"SalePrice\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1995</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>732</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>796</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>796</td>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>1362</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2</td>\n",
       "      <td>480</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Somerst</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Stone</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>1369</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>1686</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>636</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>255</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1973</td>\n",
       "      <td>1973</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>Stone</td>\n",
       "      <td>240.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>859</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>32</td>\n",
       "      <td>216</td>\n",
       "      <td>1107</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1107</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>2090</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>235</td>\n",
       "      <td>204</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>OldTown</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1931</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>952</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>FuseF</td>\n",
       "      <td>1022</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>1774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>8</td>\n",
       "      <td>Min1</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2</td>\n",
       "      <td>468</td>\n",
       "      <td>Fa</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Artery</td>\n",
       "      <td>2fmCon</td>\n",
       "      <td>1.5Unf</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>851</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>991</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1077</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "5         Lvl    AllPub    Inside       Gtl      Mitchel       Norm   \n",
       "6         Lvl    AllPub    Inside       Gtl      Somerst       Norm   \n",
       "7         Lvl    AllPub    Corner       Gtl       NWAmes       PosN   \n",
       "8         Lvl    AllPub    Inside       Gtl      OldTown     Artery   \n",
       "9         Lvl    AllPub    Corner       Gtl      BrkSide     Artery   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "5       Norm     1Fam     1.5Fin            5            5       1993   \n",
       "6       Norm     1Fam     1Story            8            5       2004   \n",
       "7       Norm     1Fam     2Story            7            6       1973   \n",
       "8       Norm     1Fam     1.5Fin            7            5       1931   \n",
       "9     Artery   2fmCon     1.5Unf            5            6       1939   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "5          1995     Gable  CompShg     VinylSd     VinylSd       None   \n",
       "6          2005     Gable  CompShg     VinylSd     VinylSd      Stone   \n",
       "7          1973     Gable  CompShg     HdBoard     HdBoard      Stone   \n",
       "8          1950     Gable  CompShg     BrkFace     Wd Shng       None   \n",
       "9          1950     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "5         0.0        TA        TA       Wood       Gd       TA           No   \n",
       "6       186.0        Gd        TA      PConc       Ex       TA           Av   \n",
       "7       240.0        TA        TA     CBlock       Gd       TA           Mn   \n",
       "8         0.0        TA        TA     BrkTil       TA       TA           No   \n",
       "9         0.0        TA        TA     BrkTil       TA       TA           No   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "5          GLQ         732          Unf           0         64          796   \n",
       "6          GLQ        1369          Unf           0        317         1686   \n",
       "7          ALQ         859          BLQ          32        216         1107   \n",
       "8          Unf           0          Unf           0        952          952   \n",
       "9          GLQ         851          Unf           0        140          991   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "5    GasA        Ex          Y      SBrkr       796       566             0   \n",
       "6    GasA        Ex          Y      SBrkr      1694         0             0   \n",
       "7    GasA        Ex          Y      SBrkr      1107       983             0   \n",
       "8    GasA        Gd          Y      FuseF      1022       752             0   \n",
       "9    GasA        Ex          Y      SBrkr      1077         0             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "5       1362             1             0         1         1             1   \n",
       "6       1694             1             0         2         0             3   \n",
       "7       2090             1             0         2         1             3   \n",
       "8       1774             0             0         2         0             2   \n",
       "9       1077             1             0         1         0             2   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "5             1          TA             5        Typ           0         NaN   \n",
       "6             1          Gd             7        Typ           1          Gd   \n",
       "7             1          TA             7        Typ           2          TA   \n",
       "8             2          TA             8       Min1           2          TA   \n",
       "9             2          TA             5        Typ           2          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "5     Attchd       1993.0          Unf           2         480         TA   \n",
       "6     Attchd       2004.0          RFn           2         636         TA   \n",
       "7     Attchd       1973.0          RFn           2         484         TA   \n",
       "8     Detchd       1931.0          Unf           2         468         Fa   \n",
       "9     Attchd       1939.0          RFn           1         205         Gd   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "5         TA          Y          40           30              0        320   \n",
       "6         TA          Y         255           57              0          0   \n",
       "7         TA          Y         235          204            228          0   \n",
       "8         TA          Y          90            0            205          0   \n",
       "9         TA          Y           0            4              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC  Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN    NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN    NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN    NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN    NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN    NaN         NaN        0      12    2008   \n",
       "5            0         0    NaN  MnPrv        Shed      700      10    2009   \n",
       "6            0         0    NaN    NaN         NaN        0       8    2007   \n",
       "7            0         0    NaN    NaN        Shed      350      11    2009   \n",
       "8            0         0    NaN    NaN         NaN        0       4    2008   \n",
       "9            0         0    NaN    NaN         NaN        0       1    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  \n",
       "5       WD        Normal     143000  \n",
       "6       WD        Normal     307000  \n",
       "7       WD        Normal     200000  \n",
       "8       WD       Abnorml     129900  \n",
       "9       WD        Normal     118000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We drop the \"Id\" column, because it will not help to predict the price. Then we describe all columns and notice several things:\n",
    "#### - the majority of the variables are categorical\n",
    "#### - some categorical variables are wrongly encoded as numerical\n",
    "#### - some numerical variables are wrongly encoded as categorical\n",
    "#### - there are several missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>91</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1452</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1423</td>\n",
       "      <td>1423</td>\n",
       "      <td>1422</td>\n",
       "      <td>1423</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1422</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1459</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>770</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>1379</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>281</td>\n",
       "      <td>54</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1454</td>\n",
       "      <td>50</td>\n",
       "      <td>925</td>\n",
       "      <td>1311</td>\n",
       "      <td>1459</td>\n",
       "      <td>1052</td>\n",
       "      <td>1382</td>\n",
       "      <td>225</td>\n",
       "      <td>1260</td>\n",
       "      <td>1445</td>\n",
       "      <td>1220</td>\n",
       "      <td>726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1141</td>\n",
       "      <td>1434</td>\n",
       "      <td>515</td>\n",
       "      <td>504</td>\n",
       "      <td>864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>906</td>\n",
       "      <td>1282</td>\n",
       "      <td>647</td>\n",
       "      <td>649</td>\n",
       "      <td>1311</td>\n",
       "      <td>953</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1428</td>\n",
       "      <td>741</td>\n",
       "      <td>1365</td>\n",
       "      <td>1334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380</td>\n",
       "      <td>870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1311</td>\n",
       "      <td>1326</td>\n",
       "      <td>1340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1267</td>\n",
       "      <td>1198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1129.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>991.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1298.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1776.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSSubClass MSZoning  LotFrontage        LotArea Street Alley  \\\n",
       "count   1460.000000     1460  1201.000000    1460.000000   1460    91   \n",
       "unique          NaN        5          NaN            NaN      2     2   \n",
       "top             NaN       RL          NaN            NaN   Pave  Grvl   \n",
       "freq            NaN     1151          NaN            NaN   1454    50   \n",
       "mean      56.897260      NaN    70.049958   10516.828082    NaN   NaN   \n",
       "std       42.300571      NaN    24.284752    9981.264932    NaN   NaN   \n",
       "min       20.000000      NaN    21.000000    1300.000000    NaN   NaN   \n",
       "25%       20.000000      NaN    59.000000    7553.500000    NaN   NaN   \n",
       "50%       50.000000      NaN    69.000000    9478.500000    NaN   NaN   \n",
       "75%       70.000000      NaN    80.000000   11601.500000    NaN   NaN   \n",
       "max      190.000000      NaN   313.000000  215245.000000    NaN   NaN   \n",
       "\n",
       "       LotShape LandContour Utilities LotConfig LandSlope Neighborhood  \\\n",
       "count      1460        1460      1460      1460      1460         1460   \n",
       "unique        4           4         2         5         3           25   \n",
       "top         Reg         Lvl    AllPub    Inside       Gtl        NAmes   \n",
       "freq        925        1311      1459      1052      1382          225   \n",
       "mean        NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "std         NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "min         NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "25%         NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "50%         NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "75%         NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "max         NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "\n",
       "       Condition1 Condition2 BldgType HouseStyle  OverallQual  OverallCond  \\\n",
       "count        1460       1460     1460       1460  1460.000000  1460.000000   \n",
       "unique          9          8        5          8          NaN          NaN   \n",
       "top          Norm       Norm     1Fam     1Story          NaN          NaN   \n",
       "freq         1260       1445     1220        726          NaN          NaN   \n",
       "mean          NaN        NaN      NaN        NaN     6.099315     5.575342   \n",
       "std           NaN        NaN      NaN        NaN     1.382997     1.112799   \n",
       "min           NaN        NaN      NaN        NaN     1.000000     1.000000   \n",
       "25%           NaN        NaN      NaN        NaN     5.000000     5.000000   \n",
       "50%           NaN        NaN      NaN        NaN     6.000000     5.000000   \n",
       "75%           NaN        NaN      NaN        NaN     7.000000     6.000000   \n",
       "max           NaN        NaN      NaN        NaN    10.000000     9.000000   \n",
       "\n",
       "          YearBuilt  YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd  \\\n",
       "count   1460.000000   1460.000000      1460     1460        1460        1460   \n",
       "unique          NaN           NaN         6        8          15          16   \n",
       "top             NaN           NaN     Gable  CompShg     VinylSd     VinylSd   \n",
       "freq            NaN           NaN      1141     1434         515         504   \n",
       "mean    1971.267808   1984.865753       NaN      NaN         NaN         NaN   \n",
       "std       30.202904     20.645407       NaN      NaN         NaN         NaN   \n",
       "min     1872.000000   1950.000000       NaN      NaN         NaN         NaN   \n",
       "25%     1954.000000   1967.000000       NaN      NaN         NaN         NaN   \n",
       "50%     1973.000000   1994.000000       NaN      NaN         NaN         NaN   \n",
       "75%     2000.000000   2004.000000       NaN      NaN         NaN         NaN   \n",
       "max     2010.000000   2010.000000       NaN      NaN         NaN         NaN   \n",
       "\n",
       "       MasVnrType   MasVnrArea ExterQual ExterCond Foundation BsmtQual  \\\n",
       "count        1452  1452.000000      1460      1460       1460     1423   \n",
       "unique          4          NaN         4         5          6        4   \n",
       "top          None          NaN        TA        TA      PConc       TA   \n",
       "freq          864          NaN       906      1282        647      649   \n",
       "mean          NaN   103.685262       NaN       NaN        NaN      NaN   \n",
       "std           NaN   181.066207       NaN       NaN        NaN      NaN   \n",
       "min           NaN     0.000000       NaN       NaN        NaN      NaN   \n",
       "25%           NaN     0.000000       NaN       NaN        NaN      NaN   \n",
       "50%           NaN     0.000000       NaN       NaN        NaN      NaN   \n",
       "75%           NaN   166.000000       NaN       NaN        NaN      NaN   \n",
       "max           NaN  1600.000000       NaN       NaN        NaN      NaN   \n",
       "\n",
       "       BsmtCond BsmtExposure BsmtFinType1   BsmtFinSF1 BsmtFinType2  \\\n",
       "count      1423         1422         1423  1460.000000         1422   \n",
       "unique        4            4            6          NaN            6   \n",
       "top          TA           No          Unf          NaN          Unf   \n",
       "freq       1311          953          430          NaN         1256   \n",
       "mean        NaN          NaN          NaN   443.639726          NaN   \n",
       "std         NaN          NaN          NaN   456.098091          NaN   \n",
       "min         NaN          NaN          NaN     0.000000          NaN   \n",
       "25%         NaN          NaN          NaN     0.000000          NaN   \n",
       "50%         NaN          NaN          NaN   383.500000          NaN   \n",
       "75%         NaN          NaN          NaN   712.250000          NaN   \n",
       "max         NaN          NaN          NaN  5644.000000          NaN   \n",
       "\n",
       "         BsmtFinSF2    BsmtUnfSF  TotalBsmtSF Heating HeatingQC CentralAir  \\\n",
       "count   1460.000000  1460.000000  1460.000000    1460      1460       1460   \n",
       "unique          NaN          NaN          NaN       6         5          2   \n",
       "top             NaN          NaN          NaN    GasA        Ex          Y   \n",
       "freq            NaN          NaN          NaN    1428       741       1365   \n",
       "mean      46.549315   567.240411  1057.429452     NaN       NaN        NaN   \n",
       "std      161.319273   441.866955   438.705324     NaN       NaN        NaN   \n",
       "min        0.000000     0.000000     0.000000     NaN       NaN        NaN   \n",
       "25%        0.000000   223.000000   795.750000     NaN       NaN        NaN   \n",
       "50%        0.000000   477.500000   991.500000     NaN       NaN        NaN   \n",
       "75%        0.000000   808.000000  1298.250000     NaN       NaN        NaN   \n",
       "max     1474.000000  2336.000000  6110.000000     NaN       NaN        NaN   \n",
       "\n",
       "       Electrical     1stFlrSF     2ndFlrSF  LowQualFinSF    GrLivArea  \\\n",
       "count        1459  1460.000000  1460.000000   1460.000000  1460.000000   \n",
       "unique          5          NaN          NaN           NaN          NaN   \n",
       "top         SBrkr          NaN          NaN           NaN          NaN   \n",
       "freq         1334          NaN          NaN           NaN          NaN   \n",
       "mean          NaN  1162.626712   346.992466      5.844521  1515.463699   \n",
       "std           NaN   386.587738   436.528436     48.623081   525.480383   \n",
       "min           NaN   334.000000     0.000000      0.000000   334.000000   \n",
       "25%           NaN   882.000000     0.000000      0.000000  1129.500000   \n",
       "50%           NaN  1087.000000     0.000000      0.000000  1464.000000   \n",
       "75%           NaN  1391.250000   728.000000      0.000000  1776.750000   \n",
       "max           NaN  4692.000000  2065.000000    572.000000  5642.000000   \n",
       "\n",
       "        BsmtFullBath  BsmtHalfBath     FullBath     HalfBath  BedroomAbvGr  \\\n",
       "count    1460.000000   1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "unique           NaN           NaN          NaN          NaN           NaN   \n",
       "top              NaN           NaN          NaN          NaN           NaN   \n",
       "freq             NaN           NaN          NaN          NaN           NaN   \n",
       "mean        0.425342      0.057534     1.565068     0.382877      2.866438   \n",
       "std         0.518911      0.238753     0.550916     0.502885      0.815778   \n",
       "min         0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "25%         0.000000      0.000000     1.000000     0.000000      2.000000   \n",
       "50%         0.000000      0.000000     2.000000     0.000000      3.000000   \n",
       "75%         1.000000      0.000000     2.000000     1.000000      3.000000   \n",
       "max         3.000000      2.000000     3.000000     2.000000      8.000000   \n",
       "\n",
       "        KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional   Fireplaces  \\\n",
       "count    1460.000000        1460   1460.000000       1460  1460.000000   \n",
       "unique           NaN           4           NaN          7          NaN   \n",
       "top              NaN          TA           NaN        Typ          NaN   \n",
       "freq             NaN         735           NaN       1360          NaN   \n",
       "mean        1.046575         NaN      6.517808        NaN     0.613014   \n",
       "std         0.220338         NaN      1.625393        NaN     0.644666   \n",
       "min         0.000000         NaN      2.000000        NaN     0.000000   \n",
       "25%         1.000000         NaN      5.000000        NaN     0.000000   \n",
       "50%         1.000000         NaN      6.000000        NaN     1.000000   \n",
       "75%         1.000000         NaN      7.000000        NaN     1.000000   \n",
       "max         3.000000         NaN     14.000000        NaN     3.000000   \n",
       "\n",
       "       FireplaceQu GarageType  GarageYrBlt GarageFinish   GarageCars  \\\n",
       "count          770       1379  1379.000000         1379  1460.000000   \n",
       "unique           5          6          NaN            3          NaN   \n",
       "top             Gd     Attchd          NaN          Unf          NaN   \n",
       "freq           380        870          NaN          605          NaN   \n",
       "mean           NaN        NaN  1978.506164          NaN     1.767123   \n",
       "std            NaN        NaN    24.689725          NaN     0.747315   \n",
       "min            NaN        NaN  1900.000000          NaN     0.000000   \n",
       "25%            NaN        NaN  1961.000000          NaN     1.000000   \n",
       "50%            NaN        NaN  1980.000000          NaN     2.000000   \n",
       "75%            NaN        NaN  2002.000000          NaN     2.000000   \n",
       "max            NaN        NaN  2010.000000          NaN     4.000000   \n",
       "\n",
       "         GarageArea GarageQual GarageCond PavedDrive   WoodDeckSF  \\\n",
       "count   1460.000000       1379       1379       1460  1460.000000   \n",
       "unique          NaN          5          5          3          NaN   \n",
       "top             NaN         TA         TA          Y          NaN   \n",
       "freq            NaN       1311       1326       1340          NaN   \n",
       "mean     472.980137        NaN        NaN        NaN    94.244521   \n",
       "std      213.804841        NaN        NaN        NaN   125.338794   \n",
       "min        0.000000        NaN        NaN        NaN     0.000000   \n",
       "25%      334.500000        NaN        NaN        NaN     0.000000   \n",
       "50%      480.000000        NaN        NaN        NaN     0.000000   \n",
       "75%      576.000000        NaN        NaN        NaN   168.000000   \n",
       "max     1418.000000        NaN        NaN        NaN   857.000000   \n",
       "\n",
       "        OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch     PoolArea  \\\n",
       "count   1460.000000    1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "unique          NaN            NaN          NaN          NaN          NaN   \n",
       "top             NaN            NaN          NaN          NaN          NaN   \n",
       "freq            NaN            NaN          NaN          NaN          NaN   \n",
       "mean      46.660274      21.954110     3.409589    15.060959     2.758904   \n",
       "std       66.256028      61.119149    29.317331    55.757415    40.177307   \n",
       "min        0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       25.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       68.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "max      547.000000     552.000000   508.000000   480.000000   738.000000   \n",
       "\n",
       "       PoolQC  Fence MiscFeature       MiscVal       MoSold       YrSold  \\\n",
       "count       7    281          54   1460.000000  1460.000000  1460.000000   \n",
       "unique      3      4           4           NaN          NaN          NaN   \n",
       "top        Gd  MnPrv        Shed           NaN          NaN          NaN   \n",
       "freq        3    157          49           NaN          NaN          NaN   \n",
       "mean      NaN    NaN         NaN     43.489041     6.321918  2007.815753   \n",
       "std       NaN    NaN         NaN    496.123024     2.703626     1.328095   \n",
       "min       NaN    NaN         NaN      0.000000     1.000000  2006.000000   \n",
       "25%       NaN    NaN         NaN      0.000000     5.000000  2007.000000   \n",
       "50%       NaN    NaN         NaN      0.000000     6.000000  2008.000000   \n",
       "75%       NaN    NaN         NaN      0.000000     8.000000  2009.000000   \n",
       "max       NaN    NaN         NaN  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "       SaleType SaleCondition      SalePrice  \n",
       "count      1460          1460    1460.000000  \n",
       "unique        9             6            NaN  \n",
       "top          WD        Normal            NaN  \n",
       "freq       1267          1198            NaN  \n",
       "mean        NaN           NaN  180921.195890  \n",
       "std         NaN           NaN   79442.502883  \n",
       "min         NaN           NaN   34900.000000  \n",
       "25%         NaN           NaN  129975.000000  \n",
       "50%         NaN           NaN  163000.000000  \n",
       "75%         NaN           NaN  214000.000000  \n",
       "max         NaN           NaN  755000.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
       "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We begin by treating the missing values. To better analyze this ,we construct a table with the missing ratio for each variable that has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Ratio\n",
       "PoolQC            99.520548\n",
       "MiscFeature       96.301370\n",
       "Alley             93.767123\n",
       "Fence             80.753425\n",
       "FireplaceQu       47.260274\n",
       "LotFrontage       17.739726\n",
       "GarageYrBlt        5.547945\n",
       "GarageType         5.547945\n",
       "GarageFinish       5.547945\n",
       "GarageQual         5.547945\n",
       "GarageCond         5.547945\n",
       "BsmtFinType2       2.602740\n",
       "BsmtExposure       2.602740\n",
       "BsmtFinType1       2.534247\n",
       "BsmtCond           2.534247\n",
       "BsmtQual           2.534247\n",
       "MasVnrArea         0.547945\n",
       "MasVnrType         0.547945\n",
       "Electrical         0.068493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_housing_missing = (df_housing.isnull().sum() / len(df_housing)) * 100\n",
    "df_housing_missing = df_housing_missing.drop(df_housing_missing[df_housing_missing == 0].index).sort_values(ascending=False)\n",
    "\n",
    "display(pd.DataFrame({'Missing Ratio' :df_housing_missing}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we apply some strategies for inputting missing values, according to some hints we can get from the dataset description. For example, for some categorical variables a missing value represents a category like \"None\", and for some numerical variables it represents the value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_none = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\",\n",
    "            \"BsmtExposure\", \"BsmtCond\", \"BsmtQual\", \"MasVnrType\"]\n",
    "for var in fill_none:\n",
    "    df_housing[var] = df_housing[var].fillna(\"None\")\n",
    "    \n",
    "fill_zero = [\"GarageYrBlt\", \"BsmtFinType2\", \"BsmtFinType1\", \"MasVnrArea\"]\n",
    "for var in fill_zero:\n",
    "    df_housing[var] = df_housing[var].fillna(0)\n",
    "\n",
    "df_housing[\"LotFrontage\"] = df_housing.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df_housing['Electrical'] = df_housing['Electrical'].fillna(df_housing['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_housing_missing = (df_housing.isnull().sum() / len(df_housing)) * 100\n",
    "df_housing_missing = df_housing_missing.drop(df_housing_missing[df_housing_missing == 0].index).sort_values(ascending=False)\n",
    "\n",
    "display(pd.DataFrame({'Missing Ratio' :df_housing_missing}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we correct some data types, according to our interpretation of numerical and categorical variables in this dataset. We represent numerical values as float numbers and categorical as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numeric_vars = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\",\n",
    "               \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\",\n",
    "               \"ScreenPorch\", \"PoolArea\", \"MiscVal\", \"SalePrice\"]\n",
    "\n",
    "categorical_vars = [v for v in df_housing.columns if v not in numeric_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandContour</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotConfig</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BldgType</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseStyle</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofStyle</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterQual</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterCond</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heating</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeatingQC</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CentralAir</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenQual</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PavedDrive</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleType</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Data Type\n",
       "MSSubClass       object\n",
       "MSZoning         object\n",
       "LotFrontage     float64\n",
       "LotArea         float64\n",
       "Street           object\n",
       "Alley            object\n",
       "LotShape         object\n",
       "LandContour      object\n",
       "Utilities        object\n",
       "LotConfig        object\n",
       "LandSlope        object\n",
       "Neighborhood     object\n",
       "Condition1       object\n",
       "Condition2       object\n",
       "BldgType         object\n",
       "HouseStyle       object\n",
       "OverallQual      object\n",
       "OverallCond      object\n",
       "YearBuilt        object\n",
       "YearRemodAdd     object\n",
       "RoofStyle        object\n",
       "RoofMatl         object\n",
       "Exterior1st      object\n",
       "Exterior2nd      object\n",
       "MasVnrType       object\n",
       "MasVnrArea      float64\n",
       "ExterQual        object\n",
       "ExterCond        object\n",
       "Foundation       object\n",
       "BsmtQual         object\n",
       "BsmtCond         object\n",
       "BsmtExposure     object\n",
       "BsmtFinType1     object\n",
       "BsmtFinSF1      float64\n",
       "BsmtFinType2     object\n",
       "BsmtFinSF2      float64\n",
       "BsmtUnfSF       float64\n",
       "TotalBsmtSF     float64\n",
       "Heating          object\n",
       "HeatingQC        object\n",
       "CentralAir       object\n",
       "Electrical       object\n",
       "1stFlrSF        float64\n",
       "2ndFlrSF        float64\n",
       "LowQualFinSF    float64\n",
       "GrLivArea       float64\n",
       "BsmtFullBath     object\n",
       "BsmtHalfBath     object\n",
       "FullBath         object\n",
       "HalfBath         object\n",
       "BedroomAbvGr     object\n",
       "KitchenAbvGr     object\n",
       "KitchenQual      object\n",
       "TotRmsAbvGrd     object\n",
       "Functional       object\n",
       "Fireplaces       object\n",
       "FireplaceQu      object\n",
       "GarageType       object\n",
       "GarageYrBlt      object\n",
       "GarageFinish     object\n",
       "GarageCars       object\n",
       "GarageArea      float64\n",
       "GarageQual       object\n",
       "GarageCond       object\n",
       "PavedDrive       object\n",
       "WoodDeckSF      float64\n",
       "OpenPorchSF     float64\n",
       "EnclosedPorch   float64\n",
       "3SsnPorch       float64\n",
       "ScreenPorch     float64\n",
       "PoolArea        float64\n",
       "PoolQC           object\n",
       "Fence            object\n",
       "MiscFeature      object\n",
       "MiscVal         float64\n",
       "MoSold           object\n",
       "YrSold           object\n",
       "SaleType         object\n",
       "SaleCondition    object\n",
       "SalePrice       float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_housing[numeric_vars] = df_housing[numeric_vars].astype(float)\n",
    "df_housing[categorical_vars] = df_housing[categorical_vars].astype(str)\n",
    "\n",
    "display(pd.DataFrame({\"Data Type\" :df_housing.dtypes}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After finishing the data preparation, we then separate the original data frame into 3: one with the numerical variables, one with the categorical variables, and one with only the response variable. This will facilitate inputting data into the neural network for training, as will be explained later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = [\"SalePrice\"]\n",
    "\n",
    "df_housing_numeric = df_housing[[var for var in numeric_vars if var not in response]]\n",
    "df_housing_categotical = df_housing[categorical_vars]\n",
    "df_housing_response = df_housing[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.199658</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>103.117123</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.431902</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>180.731373</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1129.500000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>991.500000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1298.250000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1776.750000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LotFrontage        LotArea   MasVnrArea   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1460.000000    1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean     70.199658   10516.828082   103.117123   443.639726    46.549315   \n",
       "std      22.431902    9981.264932   180.731373   456.098091   161.319273   \n",
       "min      21.000000    1300.000000     0.000000     0.000000     0.000000   \n",
       "25%      60.000000    7553.500000     0.000000     0.000000     0.000000   \n",
       "50%      70.000000    9478.500000     0.000000   383.500000     0.000000   \n",
       "75%      80.000000   11601.500000   164.250000   712.250000     0.000000   \n",
       "max     313.000000  215245.000000  1600.000000  5644.000000  1474.000000   \n",
       "\n",
       "         BsmtUnfSF  TotalBsmtSF     1stFlrSF     2ndFlrSF  LowQualFinSF  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "mean    567.240411  1057.429452  1162.626712   346.992466      5.844521   \n",
       "std     441.866955   438.705324   386.587738   436.528436     48.623081   \n",
       "min       0.000000     0.000000   334.000000     0.000000      0.000000   \n",
       "25%     223.000000   795.750000   882.000000     0.000000      0.000000   \n",
       "50%     477.500000   991.500000  1087.000000     0.000000      0.000000   \n",
       "75%     808.000000  1298.250000  1391.250000   728.000000      0.000000   \n",
       "max    2336.000000  6110.000000  4692.000000  2065.000000    572.000000   \n",
       "\n",
       "         GrLivArea   GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000    1460.000000   \n",
       "mean   1515.463699   472.980137    94.244521    46.660274      21.954110   \n",
       "std     525.480383   213.804841   125.338794    66.256028      61.119149   \n",
       "min     334.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "25%    1129.500000   334.500000     0.000000     0.000000       0.000000   \n",
       "50%    1464.000000   480.000000     0.000000    25.000000       0.000000   \n",
       "75%    1776.750000   576.000000   168.000000    68.000000       0.000000   \n",
       "max    5642.000000  1418.000000   857.000000   547.000000     552.000000   \n",
       "\n",
       "         3SsnPorch  ScreenPorch     PoolArea       MiscVal  \n",
       "count  1460.000000  1460.000000  1460.000000   1460.000000  \n",
       "mean      3.409589    15.060959     2.758904     43.489041  \n",
       "std      29.317331    55.757415    40.177307    496.123024  \n",
       "min       0.000000     0.000000     0.000000      0.000000  \n",
       "25%       0.000000     0.000000     0.000000      0.000000  \n",
       "50%       0.000000     0.000000     0.000000      0.000000  \n",
       "75%       0.000000     0.000000     0.000000      0.000000  \n",
       "max     508.000000   480.000000   738.000000  15500.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing_numeric.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>112</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>536</td>\n",
       "      <td>1151</td>\n",
       "      <td>1454</td>\n",
       "      <td>1369</td>\n",
       "      <td>925</td>\n",
       "      <td>1311</td>\n",
       "      <td>1459</td>\n",
       "      <td>1052</td>\n",
       "      <td>1382</td>\n",
       "      <td>225</td>\n",
       "      <td>1260</td>\n",
       "      <td>1445</td>\n",
       "      <td>1220</td>\n",
       "      <td>726</td>\n",
       "      <td>397</td>\n",
       "      <td>821</td>\n",
       "      <td>67</td>\n",
       "      <td>178</td>\n",
       "      <td>1141</td>\n",
       "      <td>1434</td>\n",
       "      <td>515</td>\n",
       "      <td>504</td>\n",
       "      <td>872</td>\n",
       "      <td>906</td>\n",
       "      <td>1282</td>\n",
       "      <td>647</td>\n",
       "      <td>649</td>\n",
       "      <td>1311</td>\n",
       "      <td>953</td>\n",
       "      <td>430</td>\n",
       "      <td>1256</td>\n",
       "      <td>1428</td>\n",
       "      <td>741</td>\n",
       "      <td>1365</td>\n",
       "      <td>1335</td>\n",
       "      <td>856</td>\n",
       "      <td>1378</td>\n",
       "      <td>768</td>\n",
       "      <td>913</td>\n",
       "      <td>804</td>\n",
       "      <td>1392</td>\n",
       "      <td>735</td>\n",
       "      <td>402</td>\n",
       "      <td>1360</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>870</td>\n",
       "      <td>81</td>\n",
       "      <td>605</td>\n",
       "      <td>824</td>\n",
       "      <td>1311</td>\n",
       "      <td>1326</td>\n",
       "      <td>1340</td>\n",
       "      <td>1453</td>\n",
       "      <td>1179</td>\n",
       "      <td>1406</td>\n",
       "      <td>253</td>\n",
       "      <td>338</td>\n",
       "      <td>1267</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MSSubClass MSZoning Street Alley LotShape LandContour Utilities  \\\n",
       "count        1460     1460   1460  1460     1460        1460      1460   \n",
       "unique         15        5      2     3        4           4         2   \n",
       "top            20       RL   Pave  None      Reg         Lvl    AllPub   \n",
       "freq          536     1151   1454  1369      925        1311      1459   \n",
       "\n",
       "       LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType  \\\n",
       "count       1460      1460         1460       1460       1460     1460   \n",
       "unique         5         3           25          9          8        5   \n",
       "top       Inside       Gtl        NAmes       Norm       Norm     1Fam   \n",
       "freq        1052      1382          225       1260       1445     1220   \n",
       "\n",
       "       HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle  \\\n",
       "count        1460        1460        1460      1460         1460      1460   \n",
       "unique          8          10           9       112           61         6   \n",
       "top        1Story           5           5      2006         1950     Gable   \n",
       "freq          726         397         821        67          178      1141   \n",
       "\n",
       "       RoofMatl Exterior1st Exterior2nd MasVnrType ExterQual ExterCond  \\\n",
       "count      1460        1460        1460       1460      1460      1460   \n",
       "unique        8          15          16          4         4         5   \n",
       "top     CompShg     VinylSd     VinylSd       None        TA        TA   \n",
       "freq       1434         515         504        872       906      1282   \n",
       "\n",
       "       Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinType2  \\\n",
       "count        1460     1460     1460         1460         1460         1460   \n",
       "unique          6        5        5            5            7            7   \n",
       "top         PConc       TA       TA           No          Unf          Unf   \n",
       "freq          647      649     1311          953          430         1256   \n",
       "\n",
       "       Heating HeatingQC CentralAir Electrical BsmtFullBath BsmtHalfBath  \\\n",
       "count     1460      1460       1460       1460         1460         1460   \n",
       "unique       6         5          2          5            4            3   \n",
       "top       GasA        Ex          Y      SBrkr            0            0   \n",
       "freq      1428       741       1365       1335          856         1378   \n",
       "\n",
       "       FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd  \\\n",
       "count      1460     1460         1460         1460        1460         1460   \n",
       "unique        4        3            8            4           4           12   \n",
       "top           2        0            3            1          TA            6   \n",
       "freq        768      913          804         1392         735          402   \n",
       "\n",
       "       Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish  \\\n",
       "count        1460       1460        1460       1460        1460         1460   \n",
       "unique          7          4           6          7          98            4   \n",
       "top           Typ          0        None     Attchd         0.0          Unf   \n",
       "freq         1360        690         690        870          81          605   \n",
       "\n",
       "       GarageCars GarageQual GarageCond PavedDrive PoolQC Fence MiscFeature  \\\n",
       "count        1460       1460       1460       1460   1460  1460        1460   \n",
       "unique          5          6          6          3      4     5           5   \n",
       "top             2         TA         TA          Y   None  None        None   \n",
       "freq          824       1311       1326       1340   1453  1179        1406   \n",
       "\n",
       "       MoSold YrSold SaleType SaleCondition  \n",
       "count    1460   1460     1460          1460  \n",
       "unique     12      5        9             6  \n",
       "top         6   2009       WD        Normal  \n",
       "freq      253    338     1267          1198  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing_categotical.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SalePrice\n",
       "count    1460.000000\n",
       "mean   180921.195890\n",
       "std     79442.502883\n",
       "min     34900.000000\n",
       "25%    129975.000000\n",
       "50%    163000.000000\n",
       "75%    214000.000000\n",
       "max    755000.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing_response.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The only thing remaining is to create an initial representation for the categorical variables. With PyTorch, we can represent these as label-encoded. In this case, labels are just indices to map a given value between its initial categorical representation and the corresponding embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for var in categorical_vars:\n",
    "    label_encoders[var] = LabelEncoder()\n",
    "    df_housing_categotical[var] = label_encoders[var].fit_transform(df_housing_categotical[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.214384</td>\n",
       "      <td>3.028767</td>\n",
       "      <td>0.995890</td>\n",
       "      <td>0.993836</td>\n",
       "      <td>1.942466</td>\n",
       "      <td>2.777397</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>3.019178</td>\n",
       "      <td>0.062329</td>\n",
       "      <td>12.251370</td>\n",
       "      <td>2.031507</td>\n",
       "      <td>2.008219</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>3.038356</td>\n",
       "      <td>5.986986</td>\n",
       "      <td>4.575342</td>\n",
       "      <td>72.975342</td>\n",
       "      <td>34.865753</td>\n",
       "      <td>1.410274</td>\n",
       "      <td>1.075342</td>\n",
       "      <td>9.624658</td>\n",
       "      <td>10.339726</td>\n",
       "      <td>1.762329</td>\n",
       "      <td>2.539726</td>\n",
       "      <td>3.733562</td>\n",
       "      <td>1.396575</td>\n",
       "      <td>2.724658</td>\n",
       "      <td>3.691096</td>\n",
       "      <td>2.310274</td>\n",
       "      <td>3.637671</td>\n",
       "      <td>5.559589</td>\n",
       "      <td>1.036301</td>\n",
       "      <td>1.538356</td>\n",
       "      <td>0.934932</td>\n",
       "      <td>3.682192</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>2.865753</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>2.339726</td>\n",
       "      <td>7.884247</td>\n",
       "      <td>5.749315</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>3.087671</td>\n",
       "      <td>2.485616</td>\n",
       "      <td>62.097945</td>\n",
       "      <td>1.876712</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>4.716438</td>\n",
       "      <td>4.763014</td>\n",
       "      <td>1.856164</td>\n",
       "      <td>2.991096</td>\n",
       "      <td>3.504795</td>\n",
       "      <td>1.069178</td>\n",
       "      <td>6.492466</td>\n",
       "      <td>1.815753</td>\n",
       "      <td>7.513014</td>\n",
       "      <td>3.770548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.543318</td>\n",
       "      <td>0.632017</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.249667</td>\n",
       "      <td>1.409156</td>\n",
       "      <td>0.707666</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>1.622634</td>\n",
       "      <td>0.276232</td>\n",
       "      <td>6.013735</td>\n",
       "      <td>0.868515</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>1.198277</td>\n",
       "      <td>1.911305</td>\n",
       "      <td>1.431256</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>28.852359</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>0.834998</td>\n",
       "      <td>0.599127</td>\n",
       "      <td>3.197659</td>\n",
       "      <td>3.540570</td>\n",
       "      <td>0.614274</td>\n",
       "      <td>0.693995</td>\n",
       "      <td>0.731807</td>\n",
       "      <td>0.722394</td>\n",
       "      <td>1.278630</td>\n",
       "      <td>0.949616</td>\n",
       "      <td>1.165663</td>\n",
       "      <td>1.895727</td>\n",
       "      <td>1.296332</td>\n",
       "      <td>0.295124</td>\n",
       "      <td>1.739524</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>1.051301</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.811875</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>0.830161</td>\n",
       "      <td>2.170814</td>\n",
       "      <td>0.979659</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>1.167523</td>\n",
       "      <td>1.933206</td>\n",
       "      <td>27.910915</td>\n",
       "      <td>1.191646</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>0.898787</td>\n",
       "      <td>0.802670</td>\n",
       "      <td>0.496592</td>\n",
       "      <td>0.140703</td>\n",
       "      <td>1.082912</td>\n",
       "      <td>0.372102</td>\n",
       "      <td>2.975444</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>1.552100</td>\n",
       "      <td>1.100854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass     MSZoning       Street        Alley     LotShape  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      6.214384     3.028767     0.995890     0.993836     1.942466   \n",
       "std       3.543318     0.632017     0.063996     0.249667     1.409156   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       4.000000     3.000000     1.000000     1.000000     0.000000   \n",
       "50%       5.000000     3.000000     1.000000     1.000000     3.000000   \n",
       "75%       9.000000     3.000000     1.000000     1.000000     3.000000   \n",
       "max      14.000000     4.000000     1.000000     2.000000     3.000000   \n",
       "\n",
       "       LandContour    Utilities    LotConfig    LandSlope  Neighborhood  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "mean      2.777397     0.000685     3.019178     0.062329     12.251370   \n",
       "std       0.707666     0.026171     1.622634     0.276232      6.013735   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       3.000000     0.000000     2.000000     0.000000      7.000000   \n",
       "50%       3.000000     0.000000     4.000000     0.000000     12.000000   \n",
       "75%       3.000000     0.000000     4.000000     0.000000     17.000000   \n",
       "max       3.000000     1.000000     4.000000     2.000000     24.000000   \n",
       "\n",
       "        Condition1   Condition2     BldgType   HouseStyle  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      2.031507     2.008219     0.493151     3.038356     5.986986   \n",
       "std       0.868515     0.259040     1.198277     1.911305     1.431256   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     2.000000     0.000000     2.000000     5.000000   \n",
       "50%       2.000000     2.000000     0.000000     2.000000     6.000000   \n",
       "75%       2.000000     2.000000     0.000000     5.000000     7.000000   \n",
       "max       8.000000     7.000000     4.000000     7.000000     9.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd    RoofStyle     RoofMatl  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean      4.575342    72.975342     34.865753     1.410274     1.075342   \n",
       "std       1.112799    28.852359     20.645407     0.834998     0.599127   \n",
       "min       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "25%       4.000000    55.000000     17.000000     1.000000     1.000000   \n",
       "50%       4.000000    74.000000     44.000000     1.000000     1.000000   \n",
       "75%       5.000000   101.000000     54.000000     1.000000     1.000000   \n",
       "max       8.000000   111.000000     60.000000     5.000000     7.000000   \n",
       "\n",
       "       Exterior1st  Exterior2nd   MasVnrType    ExterQual    ExterCond  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      9.624658    10.339726     1.762329     2.539726     3.733562   \n",
       "std       3.197659     3.540570     0.614274     0.693995     0.731807   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       8.000000     8.000000     1.000000     2.000000     4.000000   \n",
       "50%      12.000000    13.000000     2.000000     3.000000     4.000000   \n",
       "75%      12.000000    13.000000     2.000000     3.000000     4.000000   \n",
       "max      14.000000    15.000000     3.000000     3.000000     4.000000   \n",
       "\n",
       "        Foundation     BsmtQual     BsmtCond  BsmtExposure  BsmtFinType1  \\\n",
       "count  1460.000000  1460.000000  1460.000000   1460.000000   1460.000000   \n",
       "mean      1.396575     2.724658     3.691096      2.310274      3.637671   \n",
       "std       0.722394     1.278630     0.949616      1.165663      1.895727   \n",
       "min       0.000000     0.000000     0.000000      0.000000      0.000000   \n",
       "25%       1.000000     2.000000     4.000000      2.000000      2.000000   \n",
       "50%       1.000000     2.000000     4.000000      3.000000      3.000000   \n",
       "75%       2.000000     4.000000     4.000000      3.000000      6.000000   \n",
       "max       5.000000     4.000000     4.000000      4.000000      6.000000   \n",
       "\n",
       "       BsmtFinType2      Heating    HeatingQC   CentralAir   Electrical  \\\n",
       "count   1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean       5.559589     1.036301     1.538356     0.934932     3.682192   \n",
       "std        1.296332     0.295124     1.739524     0.246731     1.051301   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        6.000000     1.000000     0.000000     1.000000     4.000000   \n",
       "50%        6.000000     1.000000     0.000000     1.000000     4.000000   \n",
       "75%        6.000000     1.000000     4.000000     1.000000     4.000000   \n",
       "max        6.000000     5.000000     4.000000     1.000000     4.000000   \n",
       "\n",
       "       BsmtFullBath  BsmtHalfBath     FullBath     HalfBath  BedroomAbvGr  \\\n",
       "count   1460.000000   1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "mean       0.425342      0.057534     1.565068     0.382877      2.865753   \n",
       "std        0.518911      0.238753     0.550916     0.502885      0.811875   \n",
       "min        0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "25%        0.000000      0.000000     1.000000     0.000000      2.000000   \n",
       "50%        0.000000      0.000000     2.000000     0.000000      3.000000   \n",
       "75%        1.000000      0.000000     2.000000     1.000000      3.000000   \n",
       "max        3.000000      2.000000     3.000000     2.000000      7.000000   \n",
       "\n",
       "       KitchenAbvGr  KitchenQual  TotRmsAbvGrd   Functional   Fireplaces  \\\n",
       "count   1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean       1.046575     2.339726      7.884247     5.749315     0.613014   \n",
       "std        0.220338     0.830161      2.170814     0.979659     0.644666   \n",
       "min        0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "25%        1.000000     2.000000      7.000000     6.000000     0.000000   \n",
       "50%        1.000000     3.000000      8.000000     6.000000     1.000000   \n",
       "75%        1.000000     3.000000      9.000000     6.000000     1.000000   \n",
       "max        3.000000     3.000000     11.000000     6.000000     3.000000   \n",
       "\n",
       "       FireplaceQu   GarageType  GarageYrBlt  GarageFinish   GarageCars  \\\n",
       "count  1460.000000  1460.000000  1460.000000   1460.000000  1460.000000   \n",
       "mean      3.087671     2.485616    62.097945      1.876712     1.767123   \n",
       "std       1.167523     1.933206    27.910915      1.191646     0.747315   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       2.000000     1.000000    45.000000      1.000000     1.000000   \n",
       "50%       3.000000     1.000000    64.000000      2.000000     2.000000   \n",
       "75%       3.000000     5.000000    88.000000      3.000000     2.000000   \n",
       "max       5.000000     6.000000    97.000000      3.000000     4.000000   \n",
       "\n",
       "        GarageQual   GarageCond   PavedDrive       PoolQC        Fence  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      4.716438     4.763014     1.856164     2.991096     3.504795   \n",
       "std       0.898787     0.802670     0.496592     0.140703     1.082912   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       5.000000     5.000000     2.000000     3.000000     4.000000   \n",
       "50%       5.000000     5.000000     2.000000     3.000000     4.000000   \n",
       "75%       5.000000     5.000000     2.000000     3.000000     4.000000   \n",
       "max       5.000000     5.000000     2.000000     3.000000     4.000000   \n",
       "\n",
       "       MiscFeature       MoSold       YrSold     SaleType  SaleCondition  \n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      1.069178     6.492466     1.815753     7.513014       3.770548  \n",
       "std       0.372102     2.975444     1.328095     1.552100       1.100854  \n",
       "min       0.000000     0.000000     0.000000     0.000000       0.000000  \n",
       "25%       1.000000     5.000000     1.000000     8.000000       4.000000  \n",
       "50%       1.000000     7.000000     2.000000     8.000000       4.000000  \n",
       "75%       1.000000     9.000000     3.000000     8.000000       4.000000  \n",
       "max       4.000000    11.000000     4.000000     8.000000       5.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing_categotical.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we split our prepared dataset into training, validation, and test sets. We will use 80% of the data for training, 10% for validation, and 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(df_housing_response.shape[0]))\n",
    "\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_idx = idx[0:round(len(idx)*0.8)]\n",
    "test_idx = idx[round(len(idx)*0.8):round(len(idx)*0.9)]\n",
    "val_idx = idx[round(len(idx)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_num_train = df_housing_numeric.iloc[train_idx]\n",
    "df_housing_cat_train = df_housing_categotical.iloc[train_idx]\n",
    "df_housing_resp_train = df_housing_response.iloc[train_idx]\n",
    "\n",
    "df_housing_num_test = df_housing_numeric.iloc[test_idx]\n",
    "df_housing_cat_test = df_housing_categotical.iloc[test_idx]\n",
    "df_housing_resp_test = df_housing_response.iloc[test_idx]\n",
    "\n",
    "df_housing_num_val = df_housing_numeric.iloc[val_idx]\n",
    "df_housing_cat_val = df_housing_categotical.iloc[val_idx]\n",
    "df_housing_resp_val = df_housing_response.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thie function below is a generator for mini batches. In the training loop we define later, for each iteration we feed the neural network with a certain number of records from the training data given by the mini batch size we define. When creating a mini batch for the numerical variables, we also normalize then to help with the training convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data_num, data_cat, data_resp, mb_size, scale_num):\n",
    "    array_num = data_num.values.astype(np.float32)\n",
    "    if scale_num:\n",
    "        scaler = Normalizer()\n",
    "        scaler.fit(array_num)\n",
    "        array_num = scaler.transform(array_num)\n",
    "    array_cat = data_cat.values.astype(np.long)\n",
    "    array_resp = data_resp.values.astype(np.float32)\n",
    "    shuffle = np.random.permutation(len(data_resp))\n",
    "    start = 0\n",
    "    array_num = array_num[shuffle]\n",
    "    array_cat = array_cat[shuffle]\n",
    "    array_resp = array_resp[shuffle]\n",
    "    while start + mb_size <= len(data_resp):\n",
    "        yield array_num[start:start+mb_size], array_cat[start:start+mb_size], array_resp[start:start+mb_size]\n",
    "        start += mb_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we define our model hypeparameters, which are used in the architecture and training process of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = [var for var in numeric_vars if var not in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = [int(df_housing_categotical[var].nunique()) for var in categorical_vars]\n",
    "emb_dims = [min(50, (x + 1) // 2) for x in cat_dims]\n",
    "hidden_layers = [512]\n",
    "drop_rates = [0.25,0.25]\n",
    "learning_rate = 0.005\n",
    "lr_steps = [250]\n",
    "lr_gamma = 0.1\n",
    "mb_size = 32\n",
    "num_iter = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just to give us an idea of how each categorical variable is mapped to its corresponding embedding, here we print the size of each categorical variable and the corresponding size in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 5, 2, 3, 4, 4, 2, 5, 3, 25, 9, 8, 5, 8, 10, 9, 112, 61, 6, 8, 15, 16, 4, 4, 5, 6, 5, 5, 5, 7, 7, 6, 5, 2, 5, 4, 3, 4, 3, 8, 4, 4, 12, 7, 4, 6, 7, 98, 4, 5, 6, 6, 3, 4, 5, 5, 12, 5, 9, 6] \n",
      "\n",
      " [8, 3, 1, 2, 2, 2, 1, 3, 2, 13, 5, 4, 3, 4, 5, 5, 50, 31, 3, 4, 8, 8, 2, 2, 3, 3, 3, 3, 3, 4, 4, 3, 3, 1, 3, 2, 2, 2, 2, 4, 2, 2, 6, 4, 2, 3, 4, 49, 2, 3, 3, 3, 2, 2, 3, 3, 6, 3, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "print(cat_dims, \"\\n\\n\", emb_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the class defining the neural network architecture.\n",
    "\n",
    "#### We will implement the architecture described [here](https://yashuseth.blog/2018/07/22/pytorch-neural-network-for-tabular-data-with-categorical-embeddings/), but slightly modified because we will begin training locally with one hidden layer only. The architecture implemented here is illustrated by the following diagram:\n",
    "\n",
    "![model architecture](model_architecture.png)\n",
    "\n",
    "#### Notice that we can easily introduce more hidden layers, just modifying the definition of the hyperparameter \"hidden_layers\" above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.ModuleList()\n",
    "        for i in range(len(categorical_vars)):\n",
    "            self.embeddings.append(nn.Embedding(cat_dims[i], emb_dims[i]))\n",
    "        \n",
    "        self.cat_dropout = nn.Dropout(drop_rates[0])\n",
    "        \n",
    "        self.num_batchnorm = nn.BatchNorm1d(len(numeric_vars))\n",
    "        \n",
    "        self.dense_block = nn.ModuleList()\n",
    "        for l in range(len(hidden_layers)):\n",
    "            if l == 0:\n",
    "                self.dense_block.append(nn.Linear(sum(emb_dims)+len(numeric_vars), hidden_layers[l]))\n",
    "                self.dense_block.append(nn.ReLU6())\n",
    "                self.dense_block.append(nn.BatchNorm1d(hidden_layers[l]))\n",
    "                self.dense_block.append(nn.Dropout(drop_rates[1]))\n",
    "            if l > 0:\n",
    "                self.dense_block.append(nn.Linear(hidden_layers[l-1], hidden_layers[l]))\n",
    "                self.dense_block.append(nn.ReLU6())\n",
    "                self.dense_block.append(nn.BatchNorm1d(hidden_layers[l]))\n",
    "                self.dense_block.append(nn.Dropout(drop_rates[1]))\n",
    "        \n",
    "        self.dense = nn.Sequential(*self.dense_block)\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], 1)\n",
    "\n",
    "    def forward(self, Xc_list, Xn):\n",
    "        Xc_list = [self.embeddings[i](Xc_list[i]) for i in range(len(Xc_list))]\n",
    "        Xc = torch.cat(Xc_list, dim=1)\n",
    "        Xc = self.cat_dropout(Xc)\n",
    "        Xn = self.num_batchnorm(Xn)\n",
    "        X = torch.cat([Xc, Xn], dim=1)\n",
    "        X = self.dense(X)\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The loss function to be use here is the MAE (Mean Absolute Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MAE_Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        error = torch.abs(Y - X)\n",
    "        loss = torch.mean(error)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then instantiate our model object and print the number of learnable parameters. We also define a flag, which indicates if there is a GPU available for training. If so, we can send our model object and all PyTorch tensors to be processed on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "gpu_available = torch.cuda.is_available()\n",
    "print(gpu_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters: 192727\n"
     ]
    }
   ],
   "source": [
    "model = Model().cuda() if gpu_available else Model()\n",
    "print(\"Number of learnable parameters: %d\" % count_parameters(model))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we define aour model loss object, which we will try to minimize during training. We also define the optimizer and scheduler objects for the training process. Here we will use the Adam Optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = MAE_Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_steps, gamma=lr_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And finally we define the main training loop. We will iterate several times (also known as epochs) through the entire training data, performing forward and backward passes (known as backpropagation) through the network in order to minimize the loss function.\n",
    "\n",
    "#### For each of those iterations, we split the data into mini batches to perform the forward and backward passes, also keeping track of the model performance on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after itaration 0: 180999.265625\n",
      "Validation loss after itaration 0: 19959.140625\n",
      "Actual: [109500.]\tPredicted (Validation): [16.882086]\tError (Validation): [109483.12]\n",
      "\n",
      "\n",
      "Train loss after itaration 1: 181147.015625\n",
      "Validation loss after itaration 1: 20260.265625\n",
      "Actual: [119000.]\tPredicted (Validation): [102.96387]\tError (Validation): [118897.04]\n",
      "\n",
      "\n",
      "Train loss after itaration 2: 181078.953125\n",
      "Validation loss after itaration 2: 20330.298828\n",
      "Actual: [386250.]\tPredicted (Validation): [263.2044]\tError (Validation): [385986.78]\n",
      "\n",
      "\n",
      "Train loss after itaration 3: 180584.781250\n",
      "Validation loss after itaration 3: 20472.478516\n",
      "Actual: [153500.]\tPredicted (Validation): [531.44794]\tError (Validation): [152968.55]\n",
      "\n",
      "\n",
      "Train loss after itaration 4: 180655.781250\n",
      "Validation loss after itaration 4: 20541.111328\n",
      "Actual: [147000.]\tPredicted (Validation): [909.31696]\tError (Validation): [146090.69]\n",
      "\n",
      "\n",
      "Train loss after itaration 5: 180175.125000\n",
      "Validation loss after itaration 5: 20534.773438\n",
      "Actual: [224000.]\tPredicted (Validation): [1372.4415]\tError (Validation): [222627.56]\n",
      "\n",
      "\n",
      "Train loss after itaration 6: 179643.312500\n",
      "Validation loss after itaration 6: 20157.843750\n",
      "Actual: [156000.]\tPredicted (Validation): [1914.3783]\tError (Validation): [154085.62]\n",
      "\n",
      "\n",
      "Train loss after itaration 7: 179024.265625\n",
      "Validation loss after itaration 7: 19912.345703\n",
      "Actual: [82000.]\tPredicted (Validation): [2557.2139]\tError (Validation): [79442.79]\n",
      "\n",
      "\n",
      "Train loss after itaration 8: 178096.187500\n",
      "Validation loss after itaration 8: 20287.230469\n",
      "Actual: [127000.]\tPredicted (Validation): [3204.164]\tError (Validation): [123795.836]\n",
      "\n",
      "\n",
      "Train loss after itaration 9: 177308.093750\n",
      "Validation loss after itaration 9: 20134.734375\n",
      "Actual: [213000.]\tPredicted (Validation): [4071.3909]\tError (Validation): [208928.61]\n",
      "\n",
      "\n",
      "Train loss after itaration 10: 176347.781250\n",
      "Validation loss after itaration 10: 20076.867188\n",
      "Actual: [326000.]\tPredicted (Validation): [4983.908]\tError (Validation): [321016.1]\n",
      "\n",
      "\n",
      "Train loss after itaration 11: 175566.156250\n",
      "Validation loss after itaration 11: 19932.437500\n",
      "Actual: [175900.]\tPredicted (Validation): [5905.9717]\tError (Validation): [169994.03]\n",
      "\n",
      "\n",
      "Train loss after itaration 12: 174739.109375\n",
      "Validation loss after itaration 12: 19824.242188\n",
      "Actual: [154900.]\tPredicted (Validation): [7056.5317]\tError (Validation): [147843.47]\n",
      "\n",
      "\n",
      "Train loss after itaration 13: 173647.156250\n",
      "Validation loss after itaration 13: 19549.640625\n",
      "Actual: [97000.]\tPredicted (Validation): [8250.447]\tError (Validation): [88749.555]\n",
      "\n",
      "\n",
      "Train loss after itaration 14: 171952.078125\n",
      "Validation loss after itaration 14: 19301.322266\n",
      "Actual: [185000.]\tPredicted (Validation): [9388.305]\tError (Validation): [175611.69]\n",
      "\n",
      "\n",
      "Train loss after itaration 15: 170789.625000\n",
      "Validation loss after itaration 15: 18676.833984\n",
      "Actual: [153500.]\tPredicted (Validation): [10716.62]\tError (Validation): [142783.38]\n",
      "\n",
      "\n",
      "Train loss after itaration 16: 169827.546875\n",
      "Validation loss after itaration 16: 19274.218750\n",
      "Actual: [129900.]\tPredicted (Validation): [12125.748]\tError (Validation): [117774.25]\n",
      "\n",
      "\n",
      "Train loss after itaration 17: 168359.109375\n",
      "Validation loss after itaration 17: 18876.492188\n",
      "Actual: [55000.]\tPredicted (Validation): [13597.923]\tError (Validation): [41402.08]\n",
      "\n",
      "\n",
      "Train loss after itaration 18: 166856.093750\n",
      "Validation loss after itaration 18: 18741.951172\n",
      "Actual: [133000.]\tPredicted (Validation): [15094.302]\tError (Validation): [117905.695]\n",
      "\n",
      "\n",
      "Train loss after itaration 19: 164709.406250\n",
      "Validation loss after itaration 19: 18930.712891\n",
      "Actual: [175000.]\tPredicted (Validation): [16702.646]\tError (Validation): [158297.36]\n",
      "\n",
      "\n",
      "Train loss after itaration 20: 163469.203125\n",
      "Validation loss after itaration 20: 18222.265625\n",
      "Actual: [120500.]\tPredicted (Validation): [18436.61]\tError (Validation): [102063.39]\n",
      "\n",
      "\n",
      "Train loss after itaration 21: 161535.359375\n",
      "Validation loss after itaration 21: 18154.394531\n",
      "Actual: [430000.]\tPredicted (Validation): [20235.215]\tError (Validation): [409764.78]\n",
      "\n",
      "\n",
      "Train loss after itaration 22: 159833.328125\n",
      "Validation loss after itaration 22: 17782.533203\n",
      "Actual: [241500.]\tPredicted (Validation): [22016.455]\tError (Validation): [219483.55]\n",
      "\n",
      "\n",
      "Train loss after itaration 23: 158110.609375\n",
      "Validation loss after itaration 23: 17637.966797\n",
      "Actual: [271000.]\tPredicted (Validation): [23921.863]\tError (Validation): [247078.14]\n",
      "\n",
      "\n",
      "Train loss after itaration 24: 156492.890625\n",
      "Validation loss after itaration 24: 17156.242188\n",
      "Actual: [142500.]\tPredicted (Validation): [25932.629]\tError (Validation): [116567.375]\n",
      "\n",
      "\n",
      "Train loss after itaration 25: 154226.875000\n",
      "Validation loss after itaration 25: 17912.265625\n",
      "Actual: [381000.]\tPredicted (Validation): [27990.479]\tError (Validation): [353009.53]\n",
      "\n",
      "\n",
      "Train loss after itaration 26: 152276.718750\n",
      "Validation loss after itaration 26: 17442.748047\n",
      "Actual: [136905.]\tPredicted (Validation): [30132.46]\tError (Validation): [106772.54]\n",
      "\n",
      "\n",
      "Train loss after itaration 27: 149540.500000\n",
      "Validation loss after itaration 27: 17101.662109\n",
      "Actual: [175500.]\tPredicted (Validation): [32338.664]\tError (Validation): [143161.34]\n",
      "\n",
      "\n",
      "Train loss after itaration 28: 147980.187500\n",
      "Validation loss after itaration 28: 16635.322266\n",
      "Actual: [231500.]\tPredicted (Validation): [34507.59]\tError (Validation): [196992.4]\n",
      "\n",
      "\n",
      "Train loss after itaration 29: 145184.796875\n",
      "Validation loss after itaration 29: 16154.623047\n",
      "Actual: [202900.]\tPredicted (Validation): [36916.73]\tError (Validation): [165983.27]\n",
      "\n",
      "\n",
      "Train loss after itaration 30: 143275.312500\n",
      "Validation loss after itaration 30: 15398.609375\n",
      "Actual: [140000.]\tPredicted (Validation): [39223.723]\tError (Validation): [100776.28]\n",
      "\n",
      "\n",
      "Train loss after itaration 31: 140863.515625\n",
      "Validation loss after itaration 31: 15787.324219\n",
      "Actual: [150900.]\tPredicted (Validation): [41584.723]\tError (Validation): [109315.28]\n",
      "\n",
      "\n",
      "Train loss after itaration 32: 138567.812500\n",
      "Validation loss after itaration 32: 16120.523438\n",
      "Actual: [150000.]\tPredicted (Validation): [44205.2]\tError (Validation): [105794.8]\n",
      "\n",
      "\n",
      "Train loss after itaration 33: 135981.546875\n",
      "Validation loss after itaration 33: 15012.540039\n",
      "Actual: [217000.]\tPredicted (Validation): [46724.355]\tError (Validation): [170275.64]\n",
      "\n",
      "\n",
      "Train loss after itaration 34: 133293.468750\n",
      "Validation loss after itaration 34: 14407.988281\n",
      "Actual: [141000.]\tPredicted (Validation): [49324.25]\tError (Validation): [91675.75]\n",
      "\n",
      "\n",
      "Train loss after itaration 35: 130607.843750\n",
      "Validation loss after itaration 35: 14054.683594\n",
      "Actual: [175900.]\tPredicted (Validation): [52140.797]\tError (Validation): [123759.2]\n",
      "\n",
      "\n",
      "Train loss after itaration 36: 127633.039062\n",
      "Validation loss after itaration 36: 13696.267578\n",
      "Actual: [55000.]\tPredicted (Validation): [54324.36]\tError (Validation): [675.6406]\n",
      "\n",
      "\n",
      "Train loss after itaration 37: 125210.687500\n",
      "Validation loss after itaration 37: 14077.929688\n",
      "Actual: [263435.]\tPredicted (Validation): [57707.85]\tError (Validation): [205727.16]\n",
      "\n",
      "\n",
      "Train loss after itaration 38: 122216.703125\n",
      "Validation loss after itaration 38: 13613.781250\n",
      "Actual: [145000.]\tPredicted (Validation): [60510.79]\tError (Validation): [84489.21]\n",
      "\n",
      "\n",
      "Train loss after itaration 39: 119503.148438\n",
      "Validation loss after itaration 39: 13833.509766\n",
      "Actual: [136500.]\tPredicted (Validation): [63304.34]\tError (Validation): [73195.66]\n",
      "\n",
      "\n",
      "Train loss after itaration 40: 116176.687500\n",
      "Validation loss after itaration 40: 13042.988281\n",
      "Actual: [121000.]\tPredicted (Validation): [65514.984]\tError (Validation): [55485.016]\n",
      "\n",
      "\n",
      "Train loss after itaration 41: 113467.484375\n",
      "Validation loss after itaration 41: 12232.935547\n",
      "Actual: [129000.]\tPredicted (Validation): [69466.66]\tError (Validation): [59533.344]\n",
      "\n",
      "\n",
      "Train loss after itaration 42: 110108.242188\n",
      "Validation loss after itaration 42: 12407.703125\n",
      "Actual: [129000.]\tPredicted (Validation): [72626.58]\tError (Validation): [56373.42]\n",
      "\n",
      "\n",
      "Train loss after itaration 43: 107708.742188\n",
      "Validation loss after itaration 43: 12063.573242\n",
      "Actual: [136905.]\tPredicted (Validation): [75698.75]\tError (Validation): [61206.25]\n",
      "\n",
      "\n",
      "Train loss after itaration 44: 104505.000000\n",
      "Validation loss after itaration 44: 11578.195312\n",
      "Actual: [272000.]\tPredicted (Validation): [79420.12]\tError (Validation): [192579.88]\n",
      "\n",
      "\n",
      "Train loss after itaration 45: 100864.304688\n",
      "Validation loss after itaration 45: 11291.425781\n",
      "Actual: [256000.]\tPredicted (Validation): [81134.4]\tError (Validation): [174865.6]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after itaration 46: 98430.867188\n",
      "Validation loss after itaration 46: 10886.616211\n",
      "Actual: [129000.]\tPredicted (Validation): [85509.51]\tError (Validation): [43490.492]\n",
      "\n",
      "\n",
      "Train loss after itaration 47: 95254.429688\n",
      "Validation loss after itaration 47: 11141.875000\n",
      "Actual: [337000.]\tPredicted (Validation): [89182.21]\tError (Validation): [247817.78]\n",
      "\n",
      "\n",
      "Train loss after itaration 48: 92280.445312\n",
      "Validation loss after itaration 48: 10533.266602\n",
      "Actual: [134432.]\tPredicted (Validation): [91733.766]\tError (Validation): [42698.234]\n",
      "\n",
      "\n",
      "Train loss after itaration 49: 89386.343750\n",
      "Validation loss after itaration 49: 9896.232422\n",
      "Actual: [280000.]\tPredicted (Validation): [95732.08]\tError (Validation): [184267.92]\n",
      "\n",
      "\n",
      "Train loss after itaration 50: 86214.726562\n",
      "Validation loss after itaration 50: 9535.975586\n",
      "Actual: [197000.]\tPredicted (Validation): [99602.22]\tError (Validation): [97397.78]\n",
      "\n",
      "\n",
      "Train loss after itaration 51: 82673.679688\n",
      "Validation loss after itaration 51: 9396.081055\n",
      "Actual: [381000.]\tPredicted (Validation): [103151.66]\tError (Validation): [277848.34]\n",
      "\n",
      "\n",
      "Train loss after itaration 52: 79696.906250\n",
      "Validation loss after itaration 52: 8581.882812\n",
      "Actual: [85000.]\tPredicted (Validation): [78258.93]\tError (Validation): [6741.0703]\n",
      "\n",
      "\n",
      "Train loss after itaration 53: 76371.609375\n",
      "Validation loss after itaration 53: 8688.696289\n",
      "Actual: [97000.]\tPredicted (Validation): [85937.34]\tError (Validation): [11062.656]\n",
      "\n",
      "\n",
      "Train loss after itaration 54: 73202.406250\n",
      "Validation loss after itaration 54: 8494.275391\n",
      "Actual: [133000.]\tPredicted (Validation): [113699.016]\tError (Validation): [19300.984]\n",
      "\n",
      "\n",
      "Train loss after itaration 55: 69947.046875\n",
      "Validation loss after itaration 55: 7825.438477\n",
      "Actual: [180000.]\tPredicted (Validation): [118870.75]\tError (Validation): [61129.25]\n",
      "\n",
      "\n",
      "Train loss after itaration 56: 66952.953125\n",
      "Validation loss after itaration 56: 7832.666992\n",
      "Actual: [156000.]\tPredicted (Validation): [123070.195]\tError (Validation): [32929.805]\n",
      "\n",
      "\n",
      "Train loss after itaration 57: 64401.898438\n",
      "Validation loss after itaration 57: 7281.871582\n",
      "Actual: [176000.]\tPredicted (Validation): [128184.98]\tError (Validation): [47815.023]\n",
      "\n",
      "\n",
      "Train loss after itaration 58: 61006.191406\n",
      "Validation loss after itaration 58: 6882.165039\n",
      "Actual: [440000.]\tPredicted (Validation): [132474.56]\tError (Validation): [307525.44]\n",
      "\n",
      "\n",
      "Train loss after itaration 59: 57465.875000\n",
      "Validation loss after itaration 59: 6373.181152\n",
      "Actual: [337000.]\tPredicted (Validation): [137356.88]\tError (Validation): [199643.12]\n",
      "\n",
      "\n",
      "Train loss after itaration 60: 55188.945312\n",
      "Validation loss after itaration 60: 6614.706055\n",
      "Actual: [97000.]\tPredicted (Validation): [83792.63]\tError (Validation): [13207.367]\n",
      "\n",
      "\n",
      "Train loss after itaration 61: 52566.808594\n",
      "Validation loss after itaration 61: 6021.710938\n",
      "Actual: [186500.]\tPredicted (Validation): [146850.67]\tError (Validation): [39649.33]\n",
      "\n",
      "\n",
      "Train loss after itaration 62: 50275.519531\n",
      "Validation loss after itaration 62: 5280.562500\n",
      "Actual: [142500.]\tPredicted (Validation): [141581.47]\tError (Validation): [918.53125]\n",
      "\n",
      "\n",
      "Train loss after itaration 63: 47509.222656\n",
      "Validation loss after itaration 63: 5268.751953\n",
      "Actual: [280000.]\tPredicted (Validation): [155546.86]\tError (Validation): [124453.14]\n",
      "\n",
      "\n",
      "Train loss after itaration 64: 44541.238281\n",
      "Validation loss after itaration 64: 5499.839844\n",
      "Actual: [129000.]\tPredicted (Validation): [119610.61]\tError (Validation): [9389.391]\n",
      "\n",
      "\n",
      "Train loss after itaration 65: 42174.019531\n",
      "Validation loss after itaration 65: 5078.004883\n",
      "Actual: [115000.]\tPredicted (Validation): [88729.47]\tError (Validation): [26270.531]\n",
      "\n",
      "\n",
      "Train loss after itaration 66: 39316.371094\n",
      "Validation loss after itaration 66: 5045.929688\n",
      "Actual: [263435.]\tPredicted (Validation): [173800.17]\tError (Validation): [89634.83]\n",
      "\n",
      "\n",
      "Train loss after itaration 67: 37980.640625\n",
      "Validation loss after itaration 67: 4677.666992\n",
      "Actual: [430000.]\tPredicted (Validation): [179412.17]\tError (Validation): [250587.83]\n",
      "\n",
      "\n",
      "Train loss after itaration 68: 36611.914062\n",
      "Validation loss after itaration 68: 4706.877930\n",
      "Actual: [402861.]\tPredicted (Validation): [184849.28]\tError (Validation): [218011.72]\n",
      "\n",
      "\n",
      "Train loss after itaration 69: 34597.867188\n",
      "Validation loss after itaration 69: 4147.089355\n",
      "Actual: [381000.]\tPredicted (Validation): [189133.88]\tError (Validation): [191866.12]\n",
      "\n",
      "\n",
      "Train loss after itaration 70: 33303.535156\n",
      "Validation loss after itaration 70: 3720.132324\n",
      "Actual: [140000.]\tPredicted (Validation): [190950.52]\tError (Validation): [50950.516]\n",
      "\n",
      "\n",
      "Train loss after itaration 71: 32416.498047\n",
      "Validation loss after itaration 71: 3804.138916\n",
      "Actual: [150900.]\tPredicted (Validation): [165030.16]\tError (Validation): [14130.156]\n",
      "\n",
      "\n",
      "Train loss after itaration 72: 31291.691406\n",
      "Validation loss after itaration 72: 3862.326172\n",
      "Actual: [97000.]\tPredicted (Validation): [93343.52]\tError (Validation): [3656.4766]\n",
      "\n",
      "\n",
      "Train loss after itaration 73: 30621.154297\n",
      "Validation loss after itaration 73: 3554.440430\n",
      "Actual: [139000.]\tPredicted (Validation): [115286.44]\tError (Validation): [23713.562]\n",
      "\n",
      "\n",
      "Train loss after itaration 74: 29069.855469\n",
      "Validation loss after itaration 74: 3527.824219\n",
      "Actual: [147000.]\tPredicted (Validation): [151028.9]\tError (Validation): [4028.9062]\n",
      "\n",
      "\n",
      "Train loss after itaration 75: 28691.646484\n",
      "Validation loss after itaration 75: 3591.328613\n",
      "Actual: [193879.]\tPredicted (Validation): [192243.62]\tError (Validation): [1635.375]\n",
      "\n",
      "\n",
      "Train loss after itaration 76: 27006.773438\n",
      "Validation loss after itaration 76: 3411.954102\n",
      "Actual: [147000.]\tPredicted (Validation): [146992.88]\tError (Validation): [7.125]\n",
      "\n",
      "\n",
      "Train loss after itaration 77: 26463.705078\n",
      "Validation loss after itaration 77: 3330.075195\n",
      "Actual: [222000.]\tPredicted (Validation): [228283.78]\tError (Validation): [6283.7812]\n",
      "\n",
      "\n",
      "Train loss after itaration 78: 26498.792969\n",
      "Validation loss after itaration 78: 3240.670166\n",
      "Actual: [140000.]\tPredicted (Validation): [212413.08]\tError (Validation): [72413.08]\n",
      "\n",
      "\n",
      "Train loss after itaration 79: 25308.253906\n",
      "Validation loss after itaration 79: 3046.501465\n",
      "Actual: [153500.]\tPredicted (Validation): [162260.05]\tError (Validation): [8760.047]\n",
      "\n",
      "\n",
      "Train loss after itaration 80: 25445.966797\n",
      "Validation loss after itaration 80: 3250.196777\n",
      "Actual: [143000.]\tPredicted (Validation): [130878.945]\tError (Validation): [12121.055]\n",
      "\n",
      "\n",
      "Train loss after itaration 81: 23491.324219\n",
      "Validation loss after itaration 81: 3193.619629\n",
      "Actual: [133000.]\tPredicted (Validation): [131609.62]\tError (Validation): [1390.375]\n",
      "\n",
      "\n",
      "Train loss after itaration 82: 23189.707031\n",
      "Validation loss after itaration 82: 2931.020996\n",
      "Actual: [359100.]\tPredicted (Validation): [256711.06]\tError (Validation): [102388.94]\n",
      "\n",
      "\n",
      "Train loss after itaration 83: 22556.251953\n",
      "Validation loss after itaration 83: 3127.774902\n",
      "Actual: [230000.]\tPredicted (Validation): [189976.11]\tError (Validation): [40023.89]\n",
      "\n",
      "\n",
      "Train loss after itaration 84: 21932.167969\n",
      "Validation loss after itaration 84: 2895.965576\n",
      "Actual: [203000.]\tPredicted (Validation): [212141.98]\tError (Validation): [9141.984]\n",
      "\n",
      "\n",
      "Train loss after itaration 85: 22852.617188\n",
      "Validation loss after itaration 85: 2907.241699\n",
      "Actual: [206300.]\tPredicted (Validation): [182499.27]\tError (Validation): [23800.734]\n",
      "\n",
      "\n",
      "Train loss after itaration 86: 20887.751953\n",
      "Validation loss after itaration 86: 2970.006836\n",
      "Actual: [55000.]\tPredicted (Validation): [92396.5]\tError (Validation): [37396.5]\n",
      "\n",
      "\n",
      "Train loss after itaration 87: 20801.392578\n",
      "Validation loss after itaration 87: 2750.981689\n",
      "Actual: [145000.]\tPredicted (Validation): [132506.67]\tError (Validation): [12493.328]\n",
      "\n",
      "\n",
      "Train loss after itaration 88: 22362.542969\n",
      "Validation loss after itaration 88: 2832.737061\n",
      "Actual: [142500.]\tPredicted (Validation): [146148.7]\tError (Validation): [3648.7031]\n",
      "\n",
      "\n",
      "Train loss after itaration 89: 20664.048828\n",
      "Validation loss after itaration 89: 2623.687012\n",
      "Actual: [155000.]\tPredicted (Validation): [146230.33]\tError (Validation): [8769.672]\n",
      "\n",
      "\n",
      "Train loss after itaration 90: 21322.232422\n",
      "Validation loss after itaration 90: 2439.453857\n",
      "Actual: [127000.]\tPredicted (Validation): [128856.83]\tError (Validation): [1856.8281]\n",
      "\n",
      "\n",
      "Train loss after itaration 91: 20658.214844\n",
      "Validation loss after itaration 91: 2526.149902\n",
      "Actual: [139000.]\tPredicted (Validation): [134974.1]\tError (Validation): [4025.9062]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after itaration 92: 19867.560547\n",
      "Validation loss after itaration 92: 2606.932373\n",
      "Actual: [239500.]\tPredicted (Validation): [231799.11]\tError (Validation): [7700.8906]\n",
      "\n",
      "\n",
      "Train loss after itaration 93: 20291.132812\n",
      "Validation loss after itaration 93: 2738.432861\n",
      "Actual: [154900.]\tPredicted (Validation): [129078.336]\tError (Validation): [25821.664]\n",
      "\n",
      "\n",
      "Train loss after itaration 94: 20489.218750\n",
      "Validation loss after itaration 94: 2338.747070\n",
      "Actual: [127000.]\tPredicted (Validation): [125028.586]\tError (Validation): [1971.4141]\n",
      "\n",
      "\n",
      "Train loss after itaration 95: 20651.960938\n",
      "Validation loss after itaration 95: 2506.997559\n",
      "Actual: [189000.]\tPredicted (Validation): [188385.47]\tError (Validation): [614.53125]\n",
      "\n",
      "\n",
      "Train loss after itaration 96: 20149.601562\n",
      "Validation loss after itaration 96: 2578.116211\n",
      "Actual: [438780.]\tPredicted (Validation): [298270.66]\tError (Validation): [140509.34]\n",
      "\n",
      "\n",
      "Train loss after itaration 97: 19675.792969\n",
      "Validation loss after itaration 97: 2634.556396\n",
      "Actual: [156000.]\tPredicted (Validation): [162027.05]\tError (Validation): [6027.047]\n",
      "\n",
      "\n",
      "Train loss after itaration 98: 19921.515625\n",
      "Validation loss after itaration 98: 2526.739258\n",
      "Actual: [466500.]\tPredicted (Validation): [301217.16]\tError (Validation): [165282.84]\n",
      "\n",
      "\n",
      "Train loss after itaration 99: 17756.130859\n",
      "Validation loss after itaration 99: 2302.775146\n",
      "Actual: [150000.]\tPredicted (Validation): [119794.64]\tError (Validation): [30205.36]\n",
      "\n",
      "\n",
      "Train loss after itaration 100: 18170.603516\n",
      "Validation loss after itaration 100: 2560.808350\n",
      "Actual: [402861.]\tPredicted (Validation): [298172.38]\tError (Validation): [104688.625]\n",
      "\n",
      "\n",
      "Train loss after itaration 101: 19297.230469\n",
      "Validation loss after itaration 101: 2506.712891\n",
      "Actual: [126175.]\tPredicted (Validation): [124082.16]\tError (Validation): [2092.8438]\n",
      "\n",
      "\n",
      "Train loss after itaration 102: 16905.011719\n",
      "Validation loss after itaration 102: 2253.703125\n",
      "Actual: [206300.]\tPredicted (Validation): [187625.72]\tError (Validation): [18674.281]\n",
      "\n",
      "\n",
      "Train loss after itaration 103: 19114.882812\n",
      "Validation loss after itaration 103: 2304.322021\n",
      "Actual: [55000.]\tPredicted (Validation): [85280.]\tError (Validation): [30280.]\n",
      "\n",
      "\n",
      "Train loss after itaration 104: 18818.185547\n",
      "Validation loss after itaration 104: 2481.431641\n",
      "Actual: [263435.]\tPredicted (Validation): [230042.47]\tError (Validation): [33392.53]\n",
      "\n",
      "\n",
      "Train loss after itaration 105: 19279.960938\n",
      "Validation loss after itaration 105: 2506.750977\n",
      "Actual: [142500.]\tPredicted (Validation): [141538.23]\tError (Validation): [961.7656]\n",
      "\n",
      "\n",
      "Train loss after itaration 106: 17564.140625\n",
      "Validation loss after itaration 106: 2187.265381\n",
      "Actual: [139000.]\tPredicted (Validation): [124457.45]\tError (Validation): [14542.547]\n",
      "\n",
      "\n",
      "Train loss after itaration 107: 17669.548828\n",
      "Validation loss after itaration 107: 2423.307617\n",
      "Actual: [215200.]\tPredicted (Validation): [222301.19]\tError (Validation): [7101.1875]\n",
      "\n",
      "\n",
      "Train loss after itaration 108: 18157.369141\n",
      "Validation loss after itaration 108: 2453.050049\n",
      "Actual: [213000.]\tPredicted (Validation): [196712.14]\tError (Validation): [16287.859]\n",
      "\n",
      "\n",
      "Train loss after itaration 109: 17439.812500\n",
      "Validation loss after itaration 109: 2420.522949\n",
      "Actual: [156000.]\tPredicted (Validation): [157727.61]\tError (Validation): [1727.6094]\n",
      "\n",
      "\n",
      "Train loss after itaration 110: 18968.863281\n",
      "Validation loss after itaration 110: 2198.614990\n",
      "Actual: [152000.]\tPredicted (Validation): [145832.95]\tError (Validation): [6167.047]\n",
      "\n",
      "\n",
      "Train loss after itaration 111: 16852.671875\n",
      "Validation loss after itaration 111: 2433.978516\n",
      "Actual: [145000.]\tPredicted (Validation): [157099.03]\tError (Validation): [12099.031]\n",
      "\n",
      "\n",
      "Train loss after itaration 112: 17878.683594\n",
      "Validation loss after itaration 112: 2368.716309\n",
      "Actual: [200000.]\tPredicted (Validation): [136937.19]\tError (Validation): [63062.812]\n",
      "\n",
      "\n",
      "Train loss after itaration 113: 17854.292969\n",
      "Validation loss after itaration 113: 2224.054443\n",
      "Actual: [129000.]\tPredicted (Validation): [128895.99]\tError (Validation): [104.00781]\n",
      "\n",
      "\n",
      "Train loss after itaration 114: 18099.849609\n",
      "Validation loss after itaration 114: 2328.944092\n",
      "Actual: [139000.]\tPredicted (Validation): [119350.9]\tError (Validation): [19649.102]\n",
      "\n",
      "\n",
      "Train loss after itaration 115: 17638.607422\n",
      "Validation loss after itaration 115: 2325.469727\n",
      "Actual: [202900.]\tPredicted (Validation): [216641.88]\tError (Validation): [13741.875]\n",
      "\n",
      "\n",
      "Train loss after itaration 116: 18675.757812\n",
      "Validation loss after itaration 116: 2176.620361\n",
      "Actual: [176500.]\tPredicted (Validation): [190927.05]\tError (Validation): [14427.047]\n",
      "\n",
      "\n",
      "Train loss after itaration 117: 17888.835938\n",
      "Validation loss after itaration 117: 2123.851562\n",
      "Actual: [271000.]\tPredicted (Validation): [250769.94]\tError (Validation): [20230.062]\n",
      "\n",
      "\n",
      "Train loss after itaration 118: 17319.341797\n",
      "Validation loss after itaration 118: 2254.351562\n",
      "Actual: [120500.]\tPredicted (Validation): [108154.24]\tError (Validation): [12345.758]\n",
      "\n",
      "\n",
      "Train loss after itaration 119: 17109.757812\n",
      "Validation loss after itaration 119: 2127.048828\n",
      "Actual: [222000.]\tPredicted (Validation): [267747.16]\tError (Validation): [45747.156]\n",
      "\n",
      "\n",
      "Train loss after itaration 120: 16865.166016\n",
      "Validation loss after itaration 120: 2288.262207\n",
      "Actual: [90350.]\tPredicted (Validation): [131789.81]\tError (Validation): [41439.812]\n",
      "\n",
      "\n",
      "Train loss after itaration 121: 17659.521484\n",
      "Validation loss after itaration 121: 2151.507324\n",
      "Actual: [263435.]\tPredicted (Validation): [238028.12]\tError (Validation): [25406.875]\n",
      "\n",
      "\n",
      "Train loss after itaration 122: 17469.796875\n",
      "Validation loss after itaration 122: 2158.105957\n",
      "Actual: [129900.]\tPredicted (Validation): [112484.52]\tError (Validation): [17415.477]\n",
      "\n",
      "\n",
      "Train loss after itaration 123: 17311.156250\n",
      "Validation loss after itaration 123: 2302.038574\n",
      "Actual: [206300.]\tPredicted (Validation): [185235.77]\tError (Validation): [21064.234]\n",
      "\n",
      "\n",
      "Train loss after itaration 124: 15492.748047\n",
      "Validation loss after itaration 124: 2275.746338\n",
      "Actual: [142500.]\tPredicted (Validation): [140202.81]\tError (Validation): [2297.1875]\n",
      "\n",
      "\n",
      "Train loss after itaration 125: 15377.528320\n",
      "Validation loss after itaration 125: 2226.294434\n",
      "Actual: [233170.]\tPredicted (Validation): [218889.9]\tError (Validation): [14280.094]\n",
      "\n",
      "\n",
      "Train loss after itaration 126: 17700.027344\n",
      "Validation loss after itaration 126: 2224.674561\n",
      "Actual: [271000.]\tPredicted (Validation): [237666.89]\tError (Validation): [33333.11]\n",
      "\n",
      "\n",
      "Train loss after itaration 127: 16573.931641\n",
      "Validation loss after itaration 127: 2097.521973\n",
      "Actual: [149500.]\tPredicted (Validation): [141166.73]\tError (Validation): [8333.266]\n",
      "\n",
      "\n",
      "Train loss after itaration 128: 16243.843750\n",
      "Validation loss after itaration 128: 2264.852539\n",
      "Actual: [126175.]\tPredicted (Validation): [122806.99]\tError (Validation): [3368.0078]\n",
      "\n",
      "\n",
      "Train loss after itaration 129: 16282.183594\n",
      "Validation loss after itaration 129: 2192.812012\n",
      "Actual: [150000.]\tPredicted (Validation): [121456.74]\tError (Validation): [28543.258]\n",
      "\n",
      "\n",
      "Train loss after itaration 130: 15884.079102\n",
      "Validation loss after itaration 130: 2079.695312\n",
      "Actual: [402861.]\tPredicted (Validation): [342768.56]\tError (Validation): [60092.438]\n",
      "\n",
      "\n",
      "Train loss after itaration 131: 16129.075195\n",
      "Validation loss after itaration 131: 2234.558838\n",
      "Actual: [60000.]\tPredicted (Validation): [83367.02]\tError (Validation): [23367.023]\n",
      "\n",
      "\n",
      "Train loss after itaration 132: 16082.478516\n",
      "Validation loss after itaration 132: 2221.995605\n",
      "Actual: [139000.]\tPredicted (Validation): [120454.836]\tError (Validation): [18545.164]\n",
      "\n",
      "\n",
      "Train loss after itaration 133: 16417.957031\n",
      "Validation loss after itaration 133: 2200.756592\n",
      "Actual: [87500.]\tPredicted (Validation): [87683.51]\tError (Validation): [183.50781]\n",
      "\n",
      "\n",
      "Train loss after itaration 134: 17704.505859\n",
      "Validation loss after itaration 134: 2234.749512\n",
      "Actual: [386250.]\tPredicted (Validation): [316261.4]\tError (Validation): [69988.59]\n",
      "\n",
      "\n",
      "Train loss after itaration 135: 16193.232422\n",
      "Validation loss after itaration 135: 2250.142090\n",
      "Actual: [91000.]\tPredicted (Validation): [112537.766]\tError (Validation): [21537.766]\n",
      "\n",
      "\n",
      "Train loss after itaration 136: 15245.499023\n",
      "Validation loss after itaration 136: 2295.660645\n",
      "Actual: [266500.]\tPredicted (Validation): [227568.97]\tError (Validation): [38931.03]\n",
      "\n",
      "\n",
      "Train loss after itaration 137: 16016.431641\n",
      "Validation loss after itaration 137: 2222.607178\n",
      "Actual: [206300.]\tPredicted (Validation): [186679.31]\tError (Validation): [19620.688]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after itaration 138: 16140.400391\n",
      "Validation loss after itaration 138: 2203.740967\n",
      "Actual: [91000.]\tPredicted (Validation): [113293.24]\tError (Validation): [22293.242]\n",
      "\n",
      "\n",
      "Train loss after itaration 139: 16186.152344\n",
      "Validation loss after itaration 139: 2200.934082\n",
      "Actual: [131000.]\tPredicted (Validation): [137970.06]\tError (Validation): [6970.0625]\n",
      "\n",
      "\n",
      "Train loss after itaration 140: 17650.960938\n",
      "Validation loss after itaration 140: 2083.068848\n",
      "Actual: [239500.]\tPredicted (Validation): [233230.02]\tError (Validation): [6269.9844]\n",
      "\n",
      "\n",
      "Train loss after itaration 141: 16051.290039\n",
      "Validation loss after itaration 141: 2357.788330\n",
      "Actual: [197900.]\tPredicted (Validation): [166473.94]\tError (Validation): [31426.062]\n",
      "\n",
      "\n",
      "Train loss after itaration 142: 16599.855469\n",
      "Validation loss after itaration 142: 2252.575684\n",
      "Actual: [213000.]\tPredicted (Validation): [195162.73]\tError (Validation): [17837.266]\n",
      "\n",
      "\n",
      "Train loss after itaration 143: 16306.290039\n",
      "Validation loss after itaration 143: 2314.391602\n",
      "Actual: [87500.]\tPredicted (Validation): [87736.73]\tError (Validation): [236.72656]\n",
      "\n",
      "\n",
      "Train loss after itaration 144: 17230.423828\n",
      "Validation loss after itaration 144: 2172.243652\n",
      "Actual: [180000.]\tPredicted (Validation): [184977.78]\tError (Validation): [4977.7812]\n",
      "\n",
      "\n",
      "Train loss after itaration 145: 17746.343750\n",
      "Validation loss after itaration 145: 2111.505371\n",
      "Actual: [438780.]\tPredicted (Validation): [352813.66]\tError (Validation): [85966.34]\n",
      "\n",
      "\n",
      "Train loss after itaration 146: 16206.154297\n",
      "Validation loss after itaration 146: 2137.757324\n",
      "Actual: [120500.]\tPredicted (Validation): [110942.04]\tError (Validation): [9557.961]\n",
      "\n",
      "\n",
      "Train loss after itaration 147: 16050.346680\n",
      "Validation loss after itaration 147: 2379.400391\n",
      "Actual: [185000.]\tPredicted (Validation): [199028.17]\tError (Validation): [14028.172]\n",
      "\n",
      "\n",
      "Train loss after itaration 148: 17689.917969\n",
      "Validation loss after itaration 148: 2175.975830\n",
      "Actual: [190000.]\tPredicted (Validation): [176521.2]\tError (Validation): [13478.797]\n",
      "\n",
      "\n",
      "Train loss after itaration 149: 16714.398438\n",
      "Validation loss after itaration 149: 2135.572266\n",
      "Actual: [90350.]\tPredicted (Validation): [130041.71]\tError (Validation): [39691.71]\n",
      "\n",
      "\n",
      "Train loss after itaration 150: 16653.896484\n",
      "Validation loss after itaration 150: 2099.398682\n",
      "Actual: [101800.]\tPredicted (Validation): [114741.1]\tError (Validation): [12941.102]\n",
      "\n",
      "\n",
      "Train loss after itaration 151: 16590.392578\n",
      "Validation loss after itaration 151: 1969.512085\n",
      "Actual: [114500.]\tPredicted (Validation): [127474.23]\tError (Validation): [12974.227]\n",
      "\n",
      "\n",
      "Train loss after itaration 152: 15454.853516\n",
      "Validation loss after itaration 152: 2042.330566\n",
      "Actual: [85000.]\tPredicted (Validation): [87305.06]\tError (Validation): [2305.0625]\n",
      "\n",
      "\n",
      "Train loss after itaration 153: 15548.182617\n",
      "Validation loss after itaration 153: 2158.346436\n",
      "Actual: [217000.]\tPredicted (Validation): [231309.77]\tError (Validation): [14309.766]\n",
      "\n",
      "\n",
      "Train loss after itaration 154: 15926.849609\n",
      "Validation loss after itaration 154: 2131.348877\n",
      "Actual: [156932.]\tPredicted (Validation): [169951.5]\tError (Validation): [13019.5]\n",
      "\n",
      "\n",
      "Train loss after itaration 155: 17107.203125\n",
      "Validation loss after itaration 155: 2141.783447\n",
      "Actual: [203000.]\tPredicted (Validation): [215245.47]\tError (Validation): [12245.469]\n",
      "\n",
      "\n",
      "Train loss after itaration 156: 16484.320312\n",
      "Validation loss after itaration 156: 2067.870361\n",
      "Actual: [144000.]\tPredicted (Validation): [130182.04]\tError (Validation): [13817.961]\n",
      "\n",
      "\n",
      "Train loss after itaration 157: 16613.654297\n",
      "Validation loss after itaration 157: 2026.052734\n",
      "Actual: [149000.]\tPredicted (Validation): [153405.8]\tError (Validation): [4405.797]\n",
      "\n",
      "\n",
      "Train loss after itaration 158: 15452.760742\n",
      "Validation loss after itaration 158: 1909.403564\n",
      "Actual: [60000.]\tPredicted (Validation): [81135.9]\tError (Validation): [21135.898]\n",
      "\n",
      "\n",
      "Train loss after itaration 159: 16658.888672\n",
      "Validation loss after itaration 159: 2105.916992\n",
      "Actual: [149500.]\tPredicted (Validation): [140730.77]\tError (Validation): [8769.234]\n",
      "\n",
      "\n",
      "Train loss after itaration 160: 15885.780273\n",
      "Validation loss after itaration 160: 2111.377197\n",
      "Actual: [116050.]\tPredicted (Validation): [111374.88]\tError (Validation): [4675.117]\n",
      "\n",
      "\n",
      "Train loss after itaration 161: 15201.557617\n",
      "Validation loss after itaration 161: 2251.953857\n",
      "Actual: [213000.]\tPredicted (Validation): [200711.12]\tError (Validation): [12288.875]\n",
      "\n",
      "\n",
      "Train loss after itaration 162: 15587.041992\n",
      "Validation loss after itaration 162: 2068.310547\n",
      "Actual: [151000.]\tPredicted (Validation): [165424.23]\tError (Validation): [14424.234]\n",
      "\n",
      "\n",
      "Train loss after itaration 163: 16411.900391\n",
      "Validation loss after itaration 163: 2254.871094\n",
      "Actual: [222000.]\tPredicted (Validation): [248634.39]\tError (Validation): [26634.39]\n",
      "\n",
      "\n",
      "Train loss after itaration 164: 16877.980469\n",
      "Validation loss after itaration 164: 2239.494629\n",
      "Actual: [239686.]\tPredicted (Validation): [225786.83]\tError (Validation): [13899.172]\n",
      "\n",
      "\n",
      "Train loss after itaration 165: 15970.108398\n",
      "Validation loss after itaration 165: 2284.052979\n",
      "Actual: [230000.]\tPredicted (Validation): [198290.98]\tError (Validation): [31709.016]\n",
      "\n",
      "\n",
      "Train loss after itaration 166: 16257.016602\n",
      "Validation loss after itaration 166: 2188.933350\n",
      "Actual: [141000.]\tPredicted (Validation): [124789.91]\tError (Validation): [16210.094]\n",
      "\n",
      "\n",
      "Train loss after itaration 167: 15708.267578\n",
      "Validation loss after itaration 167: 2063.271729\n",
      "Actual: [233230.]\tPredicted (Validation): [211761.16]\tError (Validation): [21468.844]\n",
      "\n",
      "\n",
      "Train loss after itaration 168: 15478.977539\n",
      "Validation loss after itaration 168: 2254.899902\n",
      "Actual: [354000.]\tPredicted (Validation): [328012.2]\tError (Validation): [25987.812]\n",
      "\n",
      "\n",
      "Train loss after itaration 169: 15249.434570\n",
      "Validation loss after itaration 169: 2192.311279\n",
      "Actual: [55000.]\tPredicted (Validation): [70858.625]\tError (Validation): [15858.625]\n",
      "\n",
      "\n",
      "Train loss after itaration 170: 15541.697266\n",
      "Validation loss after itaration 170: 2276.543213\n",
      "Actual: [285000.]\tPredicted (Validation): [287078.62]\tError (Validation): [2078.625]\n",
      "\n",
      "\n",
      "Train loss after itaration 171: 14695.215820\n",
      "Validation loss after itaration 171: 2078.017822\n",
      "Actual: [190000.]\tPredicted (Validation): [176069.17]\tError (Validation): [13930.828]\n",
      "\n",
      "\n",
      "Train loss after itaration 172: 15526.121094\n",
      "Validation loss after itaration 172: 2222.362793\n",
      "Actual: [87500.]\tPredicted (Validation): [89939.98]\tError (Validation): [2439.9766]\n",
      "\n",
      "\n",
      "Train loss after itaration 173: 14447.998047\n",
      "Validation loss after itaration 173: 2327.728027\n",
      "Actual: [144900.]\tPredicted (Validation): [140775.58]\tError (Validation): [4124.422]\n",
      "\n",
      "\n",
      "Train loss after itaration 174: 16706.314453\n",
      "Validation loss after itaration 174: 2077.771240\n",
      "Actual: [153500.]\tPredicted (Validation): [112019.76]\tError (Validation): [41480.242]\n",
      "\n",
      "\n",
      "Train loss after itaration 175: 16712.898438\n",
      "Validation loss after itaration 175: 2238.028320\n",
      "Actual: [217000.]\tPredicted (Validation): [231069.03]\tError (Validation): [14069.031]\n",
      "\n",
      "\n",
      "Train loss after itaration 176: 14237.805664\n",
      "Validation loss after itaration 176: 2049.261963\n",
      "Actual: [185000.]\tPredicted (Validation): [186763.53]\tError (Validation): [1763.5312]\n",
      "\n",
      "\n",
      "Train loss after itaration 177: 17638.689453\n",
      "Validation loss after itaration 177: 2208.527100\n",
      "Actual: [154900.]\tPredicted (Validation): [123327.086]\tError (Validation): [31572.914]\n",
      "\n",
      "\n",
      "Train loss after itaration 178: 15641.736328\n",
      "Validation loss after itaration 178: 2214.724365\n",
      "Actual: [156000.]\tPredicted (Validation): [157024.75]\tError (Validation): [1024.75]\n",
      "\n",
      "\n",
      "Train loss after itaration 179: 15401.685547\n",
      "Validation loss after itaration 179: 2160.113281\n",
      "Actual: [136500.]\tPredicted (Validation): [167526.66]\tError (Validation): [31026.656]\n",
      "\n",
      "\n",
      "Train loss after itaration 180: 15597.556641\n",
      "Validation loss after itaration 180: 2187.974121\n",
      "Actual: [136500.]\tPredicted (Validation): [166867.47]\tError (Validation): [30367.469]\n",
      "\n",
      "\n",
      "Train loss after itaration 181: 14057.791992\n",
      "Validation loss after itaration 181: 2207.195801\n",
      "Actual: [126175.]\tPredicted (Validation): [127209.08]\tError (Validation): [1034.0781]\n",
      "\n",
      "\n",
      "Train loss after itaration 182: 15380.595703\n",
      "Validation loss after itaration 182: 2220.367188\n",
      "Actual: [254900.]\tPredicted (Validation): [229813.25]\tError (Validation): [25086.75]\n",
      "\n",
      "\n",
      "Train loss after itaration 183: 15314.791992\n",
      "Validation loss after itaration 183: 2193.533691\n",
      "Actual: [175000.]\tPredicted (Validation): [165687.14]\tError (Validation): [9312.859]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after itaration 184: 16752.927734\n",
      "Validation loss after itaration 184: 2056.137695\n",
      "Actual: [139000.]\tPredicted (Validation): [132033.25]\tError (Validation): [6966.75]\n",
      "\n",
      "\n",
      "Train loss after itaration 185: 14573.354492\n",
      "Validation loss after itaration 185: 2119.401855\n",
      "Actual: [272000.]\tPredicted (Validation): [212708.06]\tError (Validation): [59291.938]\n",
      "\n",
      "\n",
      "Train loss after itaration 186: 15676.001953\n",
      "Validation loss after itaration 186: 2002.214355\n",
      "Actual: [119000.]\tPredicted (Validation): [120761.945]\tError (Validation): [1761.9453]\n",
      "\n",
      "\n",
      "Train loss after itaration 187: 14931.164062\n",
      "Validation loss after itaration 187: 2150.877197\n",
      "Actual: [139000.]\tPredicted (Validation): [109598.12]\tError (Validation): [29401.883]\n",
      "\n",
      "\n",
      "Train loss after itaration 188: 15767.226562\n",
      "Validation loss after itaration 188: 2184.781250\n",
      "Actual: [213000.]\tPredicted (Validation): [195638.81]\tError (Validation): [17361.188]\n",
      "\n",
      "\n",
      "Train loss after itaration 189: 14646.892578\n",
      "Validation loss after itaration 189: 1997.820801\n",
      "Actual: [158000.]\tPredicted (Validation): [164549.6]\tError (Validation): [6549.5938]\n",
      "\n",
      "\n",
      "Train loss after itaration 190: 15544.068359\n",
      "Validation loss after itaration 190: 2214.839111\n",
      "Actual: [150000.]\tPredicted (Validation): [121626.48]\tError (Validation): [28373.523]\n",
      "\n",
      "\n",
      "Train loss after itaration 191: 14404.475586\n",
      "Validation loss after itaration 191: 2145.734863\n",
      "Actual: [205000.]\tPredicted (Validation): [195880.62]\tError (Validation): [9119.375]\n",
      "\n",
      "\n",
      "Train loss after itaration 192: 14641.006836\n",
      "Validation loss after itaration 192: 2016.664795\n",
      "Actual: [120500.]\tPredicted (Validation): [105518.03]\tError (Validation): [14981.969]\n",
      "\n",
      "\n",
      "Train loss after itaration 193: 14691.268555\n",
      "Validation loss after itaration 193: 2275.807617\n",
      "Actual: [141000.]\tPredicted (Validation): [130624.195]\tError (Validation): [10375.805]\n",
      "\n",
      "\n",
      "Train loss after itaration 194: 16093.126953\n",
      "Validation loss after itaration 194: 2093.424072\n",
      "Actual: [224000.]\tPredicted (Validation): [229354.67]\tError (Validation): [5354.672]\n",
      "\n",
      "\n",
      "Train loss after itaration 195: 14769.720703\n",
      "Validation loss after itaration 195: 2149.489746\n",
      "Actual: [155000.]\tPredicted (Validation): [145562.4]\tError (Validation): [9437.594]\n",
      "\n",
      "\n",
      "Train loss after itaration 196: 14808.651367\n",
      "Validation loss after itaration 196: 2075.907959\n",
      "Actual: [200000.]\tPredicted (Validation): [131337.11]\tError (Validation): [68662.89]\n",
      "\n",
      "\n",
      "Train loss after itaration 197: 14328.822266\n",
      "Validation loss after itaration 197: 2289.916992\n",
      "Actual: [139000.]\tPredicted (Validation): [137961.17]\tError (Validation): [1038.8281]\n",
      "\n",
      "\n",
      "Train loss after itaration 198: 15976.306641\n",
      "Validation loss after itaration 198: 2234.408203\n",
      "Actual: [214000.]\tPredicted (Validation): [195533.48]\tError (Validation): [18466.516]\n",
      "\n",
      "\n",
      "Train loss after itaration 199: 15111.126953\n",
      "Validation loss after itaration 199: 2159.743652\n",
      "Actual: [155000.]\tPredicted (Validation): [179361.97]\tError (Validation): [24361.969]\n",
      "\n",
      "\n",
      "Train loss after itaration 200: 15128.777344\n",
      "Validation loss after itaration 200: 2149.087891\n",
      "Actual: [180000.]\tPredicted (Validation): [178845.44]\tError (Validation): [1154.5625]\n",
      "\n",
      "\n",
      "Train loss after itaration 201: 15449.485352\n",
      "Validation loss after itaration 201: 2222.770996\n",
      "Actual: [144000.]\tPredicted (Validation): [127172.92]\tError (Validation): [16827.078]\n",
      "\n",
      "\n",
      "Train loss after itaration 202: 14511.048828\n",
      "Validation loss after itaration 202: 2178.958252\n",
      "Actual: [126175.]\tPredicted (Validation): [124261.56]\tError (Validation): [1913.4375]\n",
      "\n",
      "\n",
      "Train loss after itaration 203: 14611.958008\n",
      "Validation loss after itaration 203: 2003.370850\n",
      "Actual: [119000.]\tPredicted (Validation): [123507.555]\tError (Validation): [4507.5547]\n",
      "\n",
      "\n",
      "Train loss after itaration 204: 17941.865234\n",
      "Validation loss after itaration 204: 1916.875000\n",
      "Actual: [197000.]\tPredicted (Validation): [205411.61]\tError (Validation): [8411.609]\n",
      "\n",
      "\n",
      "Train loss after itaration 205: 14608.366211\n",
      "Validation loss after itaration 205: 2188.920410\n",
      "Actual: [196500.]\tPredicted (Validation): [197005.9]\tError (Validation): [505.90625]\n",
      "\n",
      "\n",
      "Train loss after itaration 206: 15543.394531\n",
      "Validation loss after itaration 206: 2423.269043\n",
      "Actual: [440000.]\tPredicted (Validation): [315123.84]\tError (Validation): [124876.16]\n",
      "\n",
      "\n",
      "Train loss after itaration 207: 15506.821289\n",
      "Validation loss after itaration 207: 2029.320068\n",
      "Actual: [359100.]\tPredicted (Validation): [276219.84]\tError (Validation): [82880.16]\n",
      "\n",
      "\n",
      "Train loss after itaration 208: 16202.930664\n",
      "Validation loss after itaration 208: 1913.925903\n",
      "Actual: [114500.]\tPredicted (Validation): [133387.31]\tError (Validation): [18887.312]\n",
      "\n",
      "\n",
      "Train loss after itaration 209: 14436.088867\n",
      "Validation loss after itaration 209: 2126.993164\n",
      "Actual: [129900.]\tPredicted (Validation): [108487.59]\tError (Validation): [21412.406]\n",
      "\n",
      "\n",
      "Train loss after itaration 210: 14411.550781\n",
      "Validation loss after itaration 210: 2089.108887\n",
      "Actual: [113000.]\tPredicted (Validation): [125474.914]\tError (Validation): [12474.914]\n",
      "\n",
      "\n",
      "Train loss after itaration 211: 15516.196289\n",
      "Validation loss after itaration 211: 2134.458496\n",
      "Actual: [129000.]\tPredicted (Validation): [133424.73]\tError (Validation): [4424.7344]\n",
      "\n",
      "\n",
      "Train loss after itaration 212: 15398.840820\n",
      "Validation loss after itaration 212: 2088.302734\n",
      "Actual: [215200.]\tPredicted (Validation): [227654.72]\tError (Validation): [12454.719]\n",
      "\n",
      "\n",
      "Train loss after itaration 213: 15291.780273\n",
      "Validation loss after itaration 213: 2066.936279\n",
      "Actual: [430000.]\tPredicted (Validation): [330834.88]\tError (Validation): [99165.125]\n",
      "\n",
      "\n",
      "Train loss after itaration 214: 16215.811523\n",
      "Validation loss after itaration 214: 2102.308594\n",
      "Actual: [139000.]\tPredicted (Validation): [132099.16]\tError (Validation): [6900.8438]\n",
      "\n",
      "\n",
      "Train loss after itaration 215: 15018.191406\n",
      "Validation loss after itaration 215: 2013.742432\n",
      "Actual: [155000.]\tPredicted (Validation): [147536.67]\tError (Validation): [7463.328]\n",
      "\n",
      "\n",
      "Train loss after itaration 216: 15198.975586\n",
      "Validation loss after itaration 216: 2041.554199\n",
      "Actual: [147000.]\tPredicted (Validation): [148383.38]\tError (Validation): [1383.375]\n",
      "\n",
      "\n",
      "Train loss after itaration 217: 15712.097656\n",
      "Validation loss after itaration 217: 1984.949951\n",
      "Actual: [141000.]\tPredicted (Validation): [130403.96]\tError (Validation): [10596.039]\n",
      "\n",
      "\n",
      "Train loss after itaration 218: 14752.321289\n",
      "Validation loss after itaration 218: 2069.806641\n",
      "Actual: [135500.]\tPredicted (Validation): [139669.86]\tError (Validation): [4169.8594]\n",
      "\n",
      "\n",
      "Train loss after itaration 219: 16222.774414\n",
      "Validation loss after itaration 219: 2103.286621\n",
      "Actual: [440000.]\tPredicted (Validation): [336187.38]\tError (Validation): [103812.625]\n",
      "\n",
      "\n",
      "Train loss after itaration 220: 15896.961914\n",
      "Validation loss after itaration 220: 2265.062012\n",
      "Actual: [109500.]\tPredicted (Validation): [94479.1]\tError (Validation): [15020.898]\n",
      "\n",
      "\n",
      "Train loss after itaration 221: 15875.310547\n",
      "Validation loss after itaration 221: 2093.406738\n",
      "Actual: [466500.]\tPredicted (Validation): [388864.94]\tError (Validation): [77635.06]\n",
      "\n",
      "\n",
      "Train loss after itaration 222: 15088.243164\n",
      "Validation loss after itaration 222: 1961.394287\n",
      "Actual: [237500.]\tPredicted (Validation): [218503.27]\tError (Validation): [18996.734]\n",
      "\n",
      "\n",
      "Train loss after itaration 223: 15801.027344\n",
      "Validation loss after itaration 223: 1889.754883\n",
      "Actual: [116050.]\tPredicted (Validation): [109995.17]\tError (Validation): [6054.828]\n",
      "\n",
      "\n",
      "Train loss after itaration 224: 15420.838867\n",
      "Validation loss after itaration 224: 2071.855957\n",
      "Actual: [87500.]\tPredicted (Validation): [89569.79]\tError (Validation): [2069.789]\n",
      "\n",
      "\n",
      "Train loss after itaration 225: 15306.769531\n",
      "Validation loss after itaration 225: 2039.831665\n",
      "Actual: [402861.]\tPredicted (Validation): [379310.84]\tError (Validation): [23550.156]\n",
      "\n",
      "\n",
      "Train loss after itaration 226: 13641.616211\n",
      "Validation loss after itaration 226: 2003.938477\n",
      "Actual: [189000.]\tPredicted (Validation): [183178.83]\tError (Validation): [5821.172]\n",
      "\n",
      "\n",
      "Train loss after itaration 227: 15465.400391\n",
      "Validation loss after itaration 227: 1990.370361\n",
      "Actual: [138500.]\tPredicted (Validation): [137423.19]\tError (Validation): [1076.8125]\n",
      "\n",
      "\n",
      "Train loss after itaration 228: 13985.829102\n",
      "Validation loss after itaration 228: 2028.792725\n",
      "Actual: [188000.]\tPredicted (Validation): [181584.84]\tError (Validation): [6415.1562]\n",
      "\n",
      "\n",
      "Train loss after itaration 229: 13892.353516\n",
      "Validation loss after itaration 229: 2091.937256\n",
      "Actual: [224900.]\tPredicted (Validation): [197005.64]\tError (Validation): [27894.36]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after itaration 230: 14052.542969\n",
      "Validation loss after itaration 230: 2142.046143\n",
      "Actual: [153500.]\tPredicted (Validation): [107736.484]\tError (Validation): [45763.516]\n",
      "\n",
      "\n",
      "Train loss after itaration 231: 15148.971680\n",
      "Validation loss after itaration 231: 1950.165649\n",
      "Actual: [82000.]\tPredicted (Validation): [97193.98]\tError (Validation): [15193.977]\n",
      "\n",
      "\n",
      "Train loss after itaration 232: 15415.201172\n",
      "Validation loss after itaration 232: 2070.210449\n",
      "Actual: [132500.]\tPredicted (Validation): [136427.4]\tError (Validation): [3927.4062]\n",
      "\n",
      "\n",
      "Train loss after itaration 233: 16521.851562\n",
      "Validation loss after itaration 233: 1802.998291\n",
      "Actual: [128500.]\tPredicted (Validation): [127600.47]\tError (Validation): [899.53125]\n",
      "\n",
      "\n",
      "Train loss after itaration 234: 15816.149414\n",
      "Validation loss after itaration 234: 2050.202148\n",
      "Actual: [100000.]\tPredicted (Validation): [117821.94]\tError (Validation): [17821.938]\n",
      "\n",
      "\n",
      "Train loss after itaration 235: 17226.937500\n",
      "Validation loss after itaration 235: 2100.764404\n",
      "Actual: [130000.]\tPredicted (Validation): [137488.19]\tError (Validation): [7488.1875]\n",
      "\n",
      "\n",
      "Train loss after itaration 236: 14640.080078\n",
      "Validation loss after itaration 236: 2013.501709\n",
      "Actual: [143000.]\tPredicted (Validation): [138493.2]\tError (Validation): [4506.797]\n",
      "\n",
      "\n",
      "Train loss after itaration 237: 15130.742188\n",
      "Validation loss after itaration 237: 2030.345947\n",
      "Actual: [203000.]\tPredicted (Validation): [215402.83]\tError (Validation): [12402.828]\n",
      "\n",
      "\n",
      "Train loss after itaration 238: 17611.865234\n",
      "Validation loss after itaration 238: 1931.282349\n",
      "Actual: [185000.]\tPredicted (Validation): [186184.88]\tError (Validation): [1184.875]\n",
      "\n",
      "\n",
      "Train loss after itaration 239: 15111.401367\n",
      "Validation loss after itaration 239: 2031.157837\n",
      "Actual: [136500.]\tPredicted (Validation): [156715.73]\tError (Validation): [20215.734]\n",
      "\n",
      "\n",
      "Train loss after itaration 240: 15567.389648\n",
      "Validation loss after itaration 240: 2037.344482\n",
      "Actual: [119000.]\tPredicted (Validation): [121392.1]\tError (Validation): [2392.1016]\n",
      "\n",
      "\n",
      "Train loss after itaration 241: 13873.715820\n",
      "Validation loss after itaration 241: 2024.323853\n",
      "Actual: [139000.]\tPredicted (Validation): [116658.13]\tError (Validation): [22341.867]\n",
      "\n",
      "\n",
      "Train loss after itaration 242: 14876.243164\n",
      "Validation loss after itaration 242: 1902.316040\n",
      "Actual: [180000.]\tPredicted (Validation): [183048.6]\tError (Validation): [3048.5938]\n",
      "\n",
      "\n",
      "Train loss after itaration 243: 17604.101562\n",
      "Validation loss after itaration 243: 2044.844238\n",
      "Actual: [175000.]\tPredicted (Validation): [170281.9]\tError (Validation): [4718.0938]\n",
      "\n",
      "\n",
      "Train loss after itaration 244: 14863.985352\n",
      "Validation loss after itaration 244: 1955.822021\n",
      "Actual: [150900.]\tPredicted (Validation): [166658.11]\tError (Validation): [15758.109]\n",
      "\n",
      "\n",
      "Train loss after itaration 245: 14977.720703\n",
      "Validation loss after itaration 245: 2373.325928\n",
      "Actual: [87500.]\tPredicted (Validation): [86438.664]\tError (Validation): [1061.3359]\n",
      "\n",
      "\n",
      "Train loss after itaration 246: 15701.590820\n",
      "Validation loss after itaration 246: 2097.740234\n",
      "Actual: [197000.]\tPredicted (Validation): [203138.52]\tError (Validation): [6138.5156]\n",
      "\n",
      "\n",
      "Train loss after itaration 247: 15635.471680\n",
      "Validation loss after itaration 247: 1748.027710\n",
      "Actual: [90350.]\tPredicted (Validation): [134637.92]\tError (Validation): [44287.92]\n",
      "\n",
      "\n",
      "Train loss after itaration 248: 16251.744141\n",
      "Validation loss after itaration 248: 2053.105957\n",
      "Actual: [174000.]\tPredicted (Validation): [176130.39]\tError (Validation): [2130.3906]\n",
      "\n",
      "\n",
      "Train loss after itaration 249: 16625.365234\n",
      "Validation loss after itaration 249: 1813.578857\n",
      "Actual: [359100.]\tPredicted (Validation): [272892.]\tError (Validation): [86208.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "num_mb = int(len(df_housing_num_train)/mb_size)\n",
    "\n",
    "for n in range(num_iter):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for k, (mb_Xn, mb_Xc, mb_Y) in enumerate(get_batch(df_housing_num_train, df_housing_cat_train, df_housing_resp_train, mb_size, True)):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # convert data from numpy arrays to torch tensors and put them on GPU, if we have one available\n",
    "        mb_Xn = torch.from_numpy(mb_Xn).cuda() if gpu_available else torch.from_numpy(mb_Xn)\n",
    "        mb_Xc = [torch.from_numpy(mb_Xc[:,i]).long().cuda() if gpu_available else torch.from_numpy(mb_Xc[:,i]).long() for i in range(len(categorical_vars))]\n",
    "        mb_Y = torch.from_numpy(mb_Y).cuda() if gpu_available else torch.from_numpy(mb_Y)\n",
    "        \n",
    "        # run forward + backward + optimize on a mini-batch\n",
    "        outputs = model(mb_Xc, mb_Xn)\n",
    "        loss = model_loss(outputs, mb_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update cost for each iteration\n",
    "        train_loss += loss.data / num_mb\n",
    "    \n",
    "    # print and save the cost for each itaration\n",
    "    print (\"Train loss after itaration %i: %f\" % (n, train_loss))\n",
    "    train_losses.append(train_loss.cpu())\n",
    "    \n",
    "    # print actual and predicted values\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for k, (mb_Xn, mb_Xc, mb_Y) in enumerate(get_batch(df_housing_num_val, df_housing_cat_val, df_housing_resp_val, mb_size, True)):\n",
    "            mb_Xn = torch.from_numpy(mb_Xn).cuda() if gpu_available else torch.from_numpy(mb_Xn)\n",
    "            mb_Xc = [torch.from_numpy(mb_Xc[:,i]).long().cuda() if gpu_available else torch.from_numpy(mb_Xc[:,i]).long() for i in range(len(categorical_vars))]\n",
    "            mb_Y = torch.from_numpy(mb_Y).cuda() if gpu_available else torch.from_numpy(mb_Y)\n",
    "            outputs = model(mb_Xc, mb_Xn)\n",
    "            loss = model_loss(outputs, mb_Y)\n",
    "            val_loss += loss.data / num_mb\n",
    "        print (\"Validation loss after itaration %i: %f\" % (n, val_loss))\n",
    "        val_losses.append(val_loss.cpu())\n",
    "        \n",
    "        idx = np.random.choice(range(mb_size))\n",
    "        actual = mb_Y[idx]\n",
    "        Xc = [mb_Xc[i][idx].view(1) for i in range(len(categorical_vars))]\n",
    "        Xn = mb_Xn[idx].view(1,len(numeric_vars))\n",
    "        predicted = model(Xc, Xn)\n",
    "        actual = actual.cpu().numpy().flatten()\n",
    "        predicted = predicted.cpu().numpy().flatten()\n",
    "        print(\"Actual: %s\\tPredicted (Validation): %s\\tError (Validation): %s\\n\\n\" % (str(actual), str(predicted), str(np.abs(actual - predicted))))\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After finishing training, we save the learned model parameters to disk. We also save the data points of the losses for training and validation that were collected during the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model/housing_model_state_dict.pt')\n",
    "\n",
    "pickle.dump(train_losses, open('./model/housing_train_losses.pickle', 'wb'))\n",
    "pickle.dump(val_losses, open('./model/housing_val_losses.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we load the data and plot the losses computed for the training and validation data during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f904c407f0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VfWd//HXJysBskAI2TEEkX0RIqC4b4CiuNdlftLWSltrp8u0U/05bZ3ptKNdbMe2o6PVn9hacalW3EXcKwhB9jVhDwlZCCSBhKzf3x854AUDuWY7yc37+Xjcx733c885+Xy9kXfO95xzrznnEBERCUaY3w2IiEjPodAQEZGgKTRERCRoCg0REQmaQkNERIKm0BARkaApNEREJGgKDRERCZpCQ0REghbhdwMdbdCgQS4rK8vvNkREepQVK1aUOeeSWlsu5EIjKyuL3Nxcv9sQEelRzGxnMMtpekpERIKm0BARkaApNEREJGgKDRERCZpCQ0REgqbQEBGRoCk0REQkaCF3nUZbbS87xIqd+yk6UENMVDjnjxjMqYP7+92WiEi3otDwvLV+L//1+qajz3/+2kZS4voQHxPJ187J5qqJaUSEa8dMRHo3c8753UOHysnJcW25Iry0qpaDtQ2kJ8Swv7qOv36yi4L9NWwoqmRjUSVDBvblX2eO4PJxqZhZJ3QuIuIfM1vhnMtpdTmFxsk553h7YwkPLNrCxqJKLh+Xym9umECfyPAO+xkiIn4LNjQ0PdUKM+OS0clcOHIw//vBVn75xmaKKw/zh5snkRLfx+/2RES6VKuT9Gb2uJmVmNm6gNozZrbKu+0ws1VePcvMagJeezhgnclmttbM8s3sQfPmeMxsoJktMrM8736AVzdvuXwzW2Nmkzp++MELDzPuOP9U/nDz6WwoqmT27z9k3Z4KP1sSEelywRzZfQKYGVhwzn3JOTfROTcR+BvwQsDLW4+85pz7RkD9IWAeMNy7HdnmXcBi59xwYLH3HGBWwLLzvPV9N3t8Gi99azrREeHc9MhS3t1U4ndLIiJdptXQcM59AJS39Jq3t3AD8PTJtmFmqUCcc26Jaz6I8iRwlffyHGC+93j+cfUnXbOlQIK3Hd8NT47luW+cScbAvnx1/nIeWLSFxqbQOjYkItKS9p5Deg5Q7JzLC6gNNbOVZva+mZ3j1dKBgoBlCrwaQLJzrgjAux8csM7uE6xzDDObZ2a5ZpZbWlravhEFKS0hhhfvOItrJ2Xw4OI87nhqBfWNTV3ys0VE/NLe0LiJY/cyioAhzrnTge8DfzWzOKClc1Rb+9M86HWcc48453KcczlJSa1+8VSH6RMZzq+uG8+/XT6KN9cX86Pn1xBqZ6OJiARq89lTZhYBXANMPlJzztUCtd7jFWa2FTiN5r2EjIDVM4BC73GxmaU654q86acjBwkKgMwTrNNtmBlfOyebysMNPLg4jxljU5gxJsXvtkREOkV79jQuBjY5545OO5lZkpmFe4+zaT6Ivc2bdqoys2necZBbgZe81RYCc73Hc4+r3+qdRTUNqDgyjdUdffvCUxmRHMu/L1xPRU293+2IiHSKYE65fRpYAowwswIzu8176UY+fwD8XGCNma0Gnge+4Zw7chD9m8CfgHxgK/C6V78PuMTM8oBLvOcArwHbvOUfBe744sPrOpHhYfzimnGUHqzl63/Opbah0e+WREQ6nK4I72AvrdrDdxas4pzhg/jf/zOZvlG6flJEur9grwjXJ/B1sDkT0/nldeP5R34Z//z0Kh0YF5GQotDoBDfkZPJ/LxvF2xuLeWb57tZXEBHpIRQaneSr04dy1rBE/uOVDezcd8jvdkREOoRCo5OEhRm/vn4C4WHG955ZRZOuGBeREKDQ6ERpCTH8ePZoPt11gLc2FPvdjohIuyk0Otk1p6eTldiXP7ybp4PiItLjKTQ6WUR4GN88fxjr9lTybK4OiotIz6bQ6ALXTsrg7FMH8W9/X8eKnfv9bkdEpM0UGl0gIjyMP948iaT+0fx04TodFBeRHkuh0UXi+0byL5eOYN2eSl5d220/QktE5KQUGl3oqtPTGZkSy32vb6K6rsHvdkREvjCFRhcKDzP+/cox7DlQw+/fyfe7HRGRL0yh0cWmZidy3eQMHv1gG1uKq/xuR0TkC1Fo+ODuWSPp3yeCe15cq4PiItKjKDR8kNg/mrtnjWT5jv08/2lB6yuIiHQTCg2fXD85k8mnDOC/XttI+aE6v9sREQmKQsMnYWHGz68eS0VNPY9+uM3vdkREgqLQ8NHIlDhmjk3hL0t3crBWp+CKSPen0PDZvHOHUXW4gQXLdvndiohIqxQaPpuYmcD0UxN56L2t2tsQkW6v1dAws8fNrMTM1gXU7jWzPWa2yrtdFvDa3WaWb2abzWxGQH2mV8s3s7sC6kPN7BMzyzOzZ8wsyqtHe8/zvdezOmrQ3c0PZ4xk36E6Hvtwu9+tiIicVDB7Gk8AM1uo/9Y5N9G7vQZgZqOBG4Ex3jr/Y2bhZhYO/BGYBYwGbvKWBbjf29ZwYD9wm1e/DdjvnDsV+K23XEiamJnAJaOT+X8fb6e2odHvdkRETqjV0HDOfQCUB7m9OcAC51ytc247kA9M8W75zrltzrk6YAEwx8wMuBB43lt/PnBVwLbme4+fBy7ylg9Jt0wdwoHqet7ZWOJ3KyIiJ9SeYxp3mtkab/pqgFdLBwK/aajAq52onggccM41HFc/Zlve6xXe8iHpnOFJJMdF89wKXewnIt1XW0PjIWAYMBEoAn7j1VvaE3BtqJ9sW59jZvPMLNfMcktLS0/Wd7cVHmZcOymD9zaXsG5Phd/tiIi0qE2h4Zwrds41OueagEdpnn6C5j2FzIBFM4DCk9TLgAQziziufsy2vNfjOcE0mXPuEedcjnMuJykpqS1D6hbmnZtNYv9ofvj8GuoamvxuR0Tkc9oUGmaWGvD0auDImVULgRu9M5+GAsOBZcByYLh3plQUzQfLFzrnHPAucJ23/lzgpYBtzfUeXwe84y0fshL6RvGzOWPZWFTJK2sKW19BRKSLRbS2gJk9DZwPDDKzAuCnwPlmNpHm6aIdwNcBnHPrzexZYAPQAHzLOdfobedO4E0gHHjcObfe+xE/AhaY2X8CK4HHvPpjwJ/NLJ/mPYwb2z3aHuDS0clkDozhhU/3cM2kDL/bERE5hoXaH+85OTkuNzfX7zba5beLtvDgO3n840cXkpYQ43c7ItILmNkK51xOa8vpivBu6NpJGTiHPlpERLodhUY3NCSxL7PGpvDYR9sprar1ux0RkaMUGt3UD2eM4HBDE398V98lLiLdh0Kjm8pO6s81p6fzzPLdVFTX+92OiAig0OjWvjw9i5r6Rp5bsbv1hUVEuoBCoxsbkxbPGVkDeHLJThqbQussNxHpmRQa3dzcs7LYVV7Ne5v1QYYi4j+FRjc3Y0wKKXF9eOLjHX63IiKi0OjuIsPDuGXqED7MK2Nr6UG/2xGRXk6h0QPcNHUIUeFhPKm9DRHxmUKjBxjUP5rZ41N5fkUBVYd1+q2I+Eeh0UPMPSuLQ3WN/H3lHr9bEZFeTKHRQ0zITGB0ahzP5OqaDRHxj0KjB/nSGZms21PJ+kJ9s5+I+EOh0YPMmZhGVEQYzy7X3oaI+EOh0YMk9I1ixpgU/r6qkMP1jX63IyK9kEKjh/lSTiYVNfW8uX6v362ISC+k0OhhzhqWSHpCDM/lFvjdioj0QgqNHiYszLh2Ujr/2FpGSeVhv9sRkV5GodEDXTkxDefglTVFfrciIr2MQqMHOnVwLKNS43h5TaHfrYhIL9NqaJjZ42ZWYmbrAmq/MrNNZrbGzF40swSvnmVmNWa2yrs9HLDOZDNba2b5ZvagmZlXH2hmi8wsz7sf4NXNWy7f+zmTOn74PdeciWms3HWA/JIqv1sRkV4kmD2NJ4CZx9UWAWOdc+OBLcDdAa9tdc5N9G7fCKg/BMwDhnu3I9u8C1jsnBsOLPaeA8wKWHaet754rp+cQVREGPM/3ul3KyLSi7QaGs65D4Dy42pvOecavKdLgYyTbcPMUoE459wS55wDngSu8l6eA8z3Hs8/rv6ka7YUSPC2I0Bi/2iunJDG3z4toKJGH2IoIl2jI45pfBV4PeD5UDNbaWbvm9k5Xi0dCDxHtMCrASQ754oAvPvBAevsPsE6Atx65ilU1zXy2lodEBeRrtGu0DCze4AG4CmvVAQMcc6dDnwf+KuZxQHWwuqtfel10OuY2TwzyzWz3NLS0uCaDwHj0uPJHtSPl1frgLiIdI02h4aZzQVmA7d4U04452qdc/u8xyuArcBpNO8lBE5hZQBH/qUrPjLt5N0f+TLsAiDzBOscwzn3iHMuxzmXk5SU1NYh9ThmxuwJaSzdto+SKl2zISKdr02hYWYzgR8BVzrnqgPqSWYW7j3Opvkg9jZv2qnKzKZ5Z03dCrzkrbYQmOs9nntc/VbvLKppQMWRaSz5zBXjU2ly8PpafayIiHS+YE65fRpYAowwswIzuw34AxALLDru1NpzgTVmthp4HviGc+7IQfRvAn8C8mneAzlyHOQ+4BIzywMu8Z4DvAZs85Z/FLijXSMNUcOTYxmZEqspKhHpEhGtLeCcu6mF8mMnWPZvwN9O8FouMLaF+j7gohbqDvhWa/0JXDEhjV+9uZk9B2pIT4jxux0RCWG6IjwEzB7ffCbyq7pCXEQ6mUIjBJyS2I8JGfG8vFqHfESkcyk0QsTs8Wms3VPBjrJDfrciIiFMoREiLvemqF7RFJWIdCKFRohIS4jhjKwBmqISkU6l0AghV0xIY3NxFZv36pNvRaRzKDRCyKyxqYSZpqhEpPMoNEJIUmw0Zw5L5OXVhXif7CIi0qEUGiHmivFp7NhXzfrCSr9bEZEQpNAIMTPHphARZvpYERHpFAqNEJPQN4pzhg/ilTVFNDVpikpEOpZCIwRdMSGNPQdq+HTXfr9bEZEQo9AIQZeMTqZfVDh//WSX362ISIhRaISg2D6RXDc5g5fXFOrLmUSkQyk0QtTcs7Kob3QsWLa79YVFRIKk0AhR2Un9mZY9UGdRiUiHUmiEsFljU8krOUh+yUG/WxGREKHQCGEzxqQA8MY6fYihiHQMhUYIS4nvw6QhCby5vtjvVkQkRCg0QtxFo5JZu6dCZ1GJSIcIKjTM7HEzKzGzdQG1gWa2yMzyvPsBXt3M7EEzyzezNWY2KWCdud7yeWY2N6A+2czWeus8aGZ2sp8hwTvvtCQAPthS5nMnIhIKgt3TeAKYeVztLmCxc244sNh7DjALGO7d5gEPQXMAAD8FpgJTgJ8GhMBD3rJH1pvZys+QII1JiyMpNpr3Npf43YqIhICgQsM59wFQflx5DjDfezwfuCqg/qRrthRIMLNUYAawyDlX7pzbDywCZnqvxTnnlrjmz/N+8rhttfQzJEhmxnmnJfFhXhn1jU1+tyMiPVx7jmkkO+eKALz7wV49HQi8oqzAq52sXtBC/WQ/Q76AWWNTqKip5y0dEBeRduqMA+HWQs21oR78DzSbZ2a5ZpZbWlr6RVbtFc4fMZjMgTHM/3iH362ISA/XntAo9qaW8O6PTJoXAJkBy2UAha3UM1qon+xnHMM594hzLsc5l5OUlNSOIYWm8DDj1mlZLNtRzsYifTmTiLRde0JjIXDkDKi5wEsB9Vu9s6imARXe1NKbwKVmNsA7AH4p8Kb3WpWZTfPOmrr1uG219DPkC7pucgbhYcZCfayIiLRDsKfcPg0sAUaYWYGZ3QbcB1xiZnnAJd5zgNeAbUA+8ChwB4Bzrhz4GbDcu/2HVwP4JvAnb52twOte/UQ/Q76gAf2imH7qIF5dU6TvDxeRNrNQ+wckJyfH5ebm+t1Gt/Ts8t3869/W8PKdZzMuI97vdkSkGzGzFc65nNaW0xXhvcilY5KJCDNeWaMpKhFpG4VGL5LQN4qzve8PD7U9TBHpGgqNXmb2+ObvD19dUOF3KyLSAyk0eplLRicTGW68orOoRKQNFBq9THxMJOcOT+K1tUU0NWmKSkS+GIVGLzR7QiqFFYf5dNd+v1sRkR5GodELXTwqmeiIMF5Zo2/0E5EvRqHRC8X2ieSCEYN5dW0RjZqiEpEvQKHRS10xIY3Sqlo+2b7P71ZEpAdRaPRSF44cTN+ocF5erSkqEQmeQqOXiokK5+JRybyxrkhfziQiQVNo9GKXj09lf3U9y7cf/6WMIiItU2j0YmefOoio8DDe2aTvDxeR4Cg0erF+0RFMzR7IO5sVGiISHIVGL3fhyMFsKz3Ezn2H/G5FRHoAhUYvd+HIwQAs2lDscyci0hMoNHq5UxL7MTY9Tl8DKyJBUWgIV05IY01BBdvLNEUlIien0BBmj08D4GXtbYhIKxQaQlpCDDmnDOD1dXv9bkVEujmFhgAwc2wKG4sq2bWv2u9WRKQba3NomNkIM1sVcKs0s++a2b1mtiegflnAOnebWb6ZbTazGQH1mV4t38zuCqgPNbNPzCzPzJ4xs6i2D1VOZsaYFADeXK+9DRE5sTaHhnNus3NuonNuIjAZqAZe9F7+7ZHXnHOvAZjZaOBGYAwwE/gfMws3s3Dgj8AsYDRwk7cswP3etoYD+4Hb2tqvnFzmwL6MTo3jDYWGiJxER01PXQRsdc7tPMkyc4AFzrla59x2IB+Y4t3ynXPbnHN1wAJgjpkZcCHwvLf+fOCqDupXWjBzbAqf7tpPSeVhv1sRkW6qo0LjRuDpgOd3mtkaM3vczAZ4tXRgd8AyBV7tRPVE4IBzruG4unSSGWNScA7e0oV+InIC7Q4N7zjDlcBzXukhYBgwESgCfnNk0RZWd22ot9TDPDPLNbPc0tLSL9C9BDotuT9DB/XTcQ0ROaGO2NOYBXzqnCsGcM4VO+canXNNwKM0Tz9B855CZsB6GUDhSeplQIKZRRxX/xzn3CPOuRznXE5SUlIHDKl3MjMuHZPMkq37qKiu97sdEemGOiI0biJgasrMUgNeuxpY5z1eCNxoZtFmNhQYDiwDlgPDvTOlomie6lronHPAu8B13vpzgZc6oF85iZljUmhocizepCkqEfm8doWGmfUFLgFeCCj/0szWmtka4ALgewDOufXAs8AG4A3gW94eSQNwJ/AmsBF41lsW4EfA980sn+ZjHI+1p19p3YSMBJLjojVFJSItimh9kRNzzlXT/I95YO3/nGT5nwM/b6H+GvBaC/VtfDa9JV0gLMyYMSaFZ3N3U1PXSExUuN8tiUg3oivC5XNmjknhcH0T7+rLmUTkOAoN+ZwpQwcyqH+UPsBQRD5HoSGfExEexuXjUnlnUwlVh3UWlYh8RqEhLbpyYhq1DU28tV5nUYnIZxQa0qJJQwZwSmJfnsnd3frCItJrKDSkRWbGTVOGsGx7OXnFVX63IyLdhEJDTuj6yRlEhhtPfbLL71ZEpJtQaMgJJfaP5qKRybyxbi/NF+iLSG+n0JCTumjUYPZWHmZ9YaXfrYhIN6DQkJO6YORgzOCdTbrQT0QUGtKKQf2jmZiZwOKNOvVWRBQaEoSLRg5mdUGFvtFPRBQa0rqLRiUD6LOoREShIa0bmRJLWnwf3t6o0BDp7RQa0ioz48JRg/kor4zD9Y1+tyMiPlJoSFBmjU2lpr6RV9YU+d2KiPhIoSFBOWtYIiOSY3n0g2260E+kF1NoSFDMjNvPzWZzcRUf5JX53Y6I+EShIUG7ckIaif2ieGrpTr9bERGfKDQkaFERYVw3OYPFm0p0zYZIL9Xu0DCzHWa21sxWmVmuVxtoZovMLM+7H+DVzcweNLN8M1tjZpMCtjPXWz7PzOYG1Cd728/31rX29ixt96UzMmlscjy3osDvVkTEBx21p3GBc26icy7He34XsNg5NxxY7D0HmAUM927zgIegOWSAnwJTgSnAT48EjbfMvID1ZnZQz9IG2Un9mX5qIk8u2UFdQ5Pf7YhIF+us6ak5wHzv8XzgqoD6k67ZUiDBzFKBGcAi51y5c24/sAiY6b0W55xb4ppP2XkyYFvik9vPyaa4spaXVxf63YqIdLGOCA0HvGVmK8xsnldLds4VAXj3g716OhD4/aEFXu1k9YIW6uKj805LYkRyLI99tN3vVkSki3VEaEx3zk2ieerpW2Z27kmWbel4hGtD/diNms0zs1wzyy0tLQ2mZ2kHM+OWaUPYUFTJ+sIKv9sRkS7U7tBwzhV69yXAizQfkyj2ppbw7o98aFEBkBmwegZQ2Eo9o4X68T084pzLcc7lJCUltXdIEoQrJ6QRFR7Gc7k6IC7Sm7QrNMysn5nFHnkMXAqsAxYCR86Amgu85D1eCNzqnUU1Dajwpq/eBC41swHeAfBLgTe916rMbJp31tStAdsSHyX0jeKSMcm8tGqPDoiL9CLt3dNIBj4ys9XAMuBV59wbwH3AJWaWB1ziPQd4DdgG5AOPAncAOOfKgZ8By73bf3g1gG8Cf/LW2Qq83s6epYNcNzmD/dX1+oImkV7EQu1zhHJyclxubq7fbfQKjU2Os+5bzNi0eB778hl+tyMi7WBmKwIumzghXREubRYeZlwzKYP3tpRSUqUrxEV6A4WGtMt1kzNobHK8+Okev1sRkS6g0JB2GZbUn0lDEnh+RYE+Ml2kF1BoSLtdn5NJXslBVhfomg2RUKfQkHabPT6VPpFhPJe7u/WFRaRHU2hIu8X2iWTW2FQWri7Ud4iLhDiFhnSI6yZnUHW4gbc26JoNkVCm0JAOcWZ2IukJMTz83lZqG7S3IRKqFBrSIcLCjJ9eMZoNRZX87JUNfrcjIp1EoSEd5tIxKXz93Gz+snQXf1+p6zZEQpFCQzrUD2eMYMrQgdz9wloK9lf73Y6IdDCFhnSoiPAwfveliTQ6x+8X5/vdjoh0MIWGdLi0hBhumTqE5z8tYFvpQb/bEZEOpNCQTnHH+afSLyqcO/+6kpo6nU0lEioUGtIpkmKj+e+bTmfj3kq+8ZcVHKxt8LslEekACg3pNBeMGMz914zno/wybnxkCZWH6/1uSUTaSaEhneqGMzJ59NbJbCqq4rYnllNSqe/dEOnJFBrS6S4cmcxvvzSRNQUVXPzA+6zbo0/DFempFBrSJa6YkMbr3zmHPpHh/OC51dQ1NPndkoi0gUJDukx2Un9+cfU4Nu2t4orff8QifbihSI+j0JAudfHoZB64YQINTU18Z8FKCg/U+N2SiHwBbQ4NM8s0s3fNbKOZrTez73j1e81sj5mt8m6XBaxzt5nlm9lmM5sRUJ/p1fLN7K6A+lAz+8TM8szsGTOLamu/0n1cMymDJ74yhSbnuOuFtZQfqtNXxYr0EO3Z02gA/sU5NwqYBnzLzEZ7r/3WOTfRu70G4L12IzAGmAn8j5mFm1k48EdgFjAauClgO/d72xoO7Adua0e/0o1kDuzL3bNG8WFeKZP/cxEjfvwGf1m60++2RKQVEW1d0TlXBBR5j6vMbCOQfpJV5gALnHO1wHYzywemeK/lO+e2AZjZAmCOt70LgZu9ZeYD9wIPtbVn6V7mnpXFmcMSeWV1Ict2lPOTl9bx9sZixqfH8/1LR/jdnoi0oEOOaZhZFnA68IlXutPM1pjZ42Y2wKulA4FfIl3g1U5UTwQOOOcajqtLCDktOZbvXzqCx798BheNSmbz3ioefCef1bsP+N2aiLSg3aFhZv2BvwHfdc5V0rwnMAyYSPOeyG+OLNrC6q4N9ZZ6mGdmuWaWW1pa+gVHIN1B36gIHr01h0XfP4+B/aL4z1c3sKPskN9tichx2hUaZhZJc2A85Zx7AcA5V+yca3TONQGP8tkUVAGQGbB6BlB4knoZkGBmEcfVP8c594hzLsc5l5OUlNSeIYnP+kdH8MMZI1i+Yz/n//o9vrtgJSVVh3ljXRG/XbTl6AHz2oZGHTwX8UGbj2mYmQGPARudcw8E1FO94x0AVwPrvMcLgb+a2QNAGjAcWEbzHsVwMxsK7KH5YPnNzjlnZu8C1wELgLnAS23tV3qOm6YMYfqwQTybu5tHPtjGog3FHPI+Kff0IQmcnjmAy3//IVOyBvLAlyb63K1I72Jt/WvNzM4GPgTWAkcu7/2/wE00T005YAfw9SMhYmb3AF+l+cyr7zrnXvfqlwG/A8KBx51zP/fq2TQHxkBgJfBP3oH0E8rJyXG5ubltGpN0P9vLDvHzVzcyoG8kS7bto390BFmJ/Xhj/V4A5kxMY2vpQX44YyTnnfbZXmZTk6O6vpH+0W3+u0ikVzGzFc65nFaXC7VdfIVG6HplTSHffnolzsHXz8vmrfXFbC87RFJsNKVVtdx65in0iQznk+3l5BVXUVPfyIzRKXzz/GEM7BdFdGQYg2P7+D0MkW5JoSEhqbjyMFWHGxiW1I89B2ooP1THacmx/PKNzTz+j+1EhBlnZA1kZGoskeFhLFi2i8rDzSfgpSfE8O4Pzicy3Fi4upBp2Yn0jQpnW+khUuL7sGhDMZePS2VAv2OvIa1taCQ6ItyP4Yp0GYWG9DpbiqtI6Bt5zN5E1eF6Xly5h4L9NTzywTbuu2Ycew7U8Pt38pkxJpnoiHAWrv7s/IrZ41P5w82TaGxyHK5vpPxQHXP++A++Oj2LOy8cfnS5mrpG+kSG8acPt7Oz/BB3zRqlqTDp0YINDf2WS8g4LTn2c7XYPpHcemYWzjmWbN3HPX9fR2OTIzku+ugHJl42LoWRKXGUHazlySU7iYtZy8f5ZezeX0PGgBjKD9Xx8PvbMDNeXl1IdV0ju8qrGTqoH9u904I/yivjnstHc/6IJCLDw1i+o5z3N5eSNagfo1JjGZMWD8CufdUsXL2H28/NPuney3ubSyipquWGnMzPvbbvYC0vrSrk5qlD6BP52TaWbN3Hy2sK+ecLh5MS34e1BRUs3baPr549lPCwls5g7zpNTY75S3Zw+fhU36YIqw7Xc+vjy7hr5kimZif60sOJNDU5wrz3aEfZIdYVVjB7fNoxy5QdrOXdTSVcNzmD5vOQ/KHQkF7BzPi3y0fxh3fzmT0+lemnDuK8X71HeJhx7xVjGBzXh8P1jSzdto/ncnczNj2e0WlxvLZ2L187eyh/+mg7v3pzMxMyExiW1J/Lx6eyeGMxt0x9yHxYAAAMIElEQVQdwuXjU7nnxXXc/mQu0RFhjEyNY23BAZoCduJ/PHs0t509lJ+/toE31xezsaiK+64dR2yfyM/1unLXfuY9uYK6xibSE2KYfuqgo681NTm++8wqPswro/xQHZeNSwXgz0t38vSyXQDsLq/m4X+azDf+soI9B2pYtqOcC0YMJi4mgrOGDWKgN/1WWlXL7U/mMio1lsvGpTKofzQjU2J5f0spEzMTSOj72TTdluIqFizbzcWjBnNWQD8ns3LXfpZtLyc7qT8D+kby7y9vYOWuAzx40+ktLr9rXzVbiqu4eHRyUNv/ot7dXMrKXQd4etmubhEaB2sbqK5tIK/kIN9+eiUP/9NkpgwdyE8WrueDLaWMS4/nlMR+R5f/77fz+PPSnWQn9WfyKQOO2VZNXSNvbdjL5FMGkDGgb6f2rekp6bV+9/YWYiLD+fp5w47WmpocZhz9S660qpak2Gh+8dpGausb+fHs0USEf/7ypvrGJt7eUEzuzv2s2n2A4YP7c/dloyg7WMu9C9ezatcBnvjqFK57+GNGpsSxsaiSyHCjT2Q4WYn9GJcRz9aSgzQ5x6rdB0iJ70NkWBg19Y088ZUpvLhyD1uKq9hbcZgNRZVkD+rH9n2HCPzf9xvnDWNQ/yj+89WNpCfEsOdADTdNyeTZ3AIavQTLSuzL0/OmUVpVyz0vrmNLcRUNTY7GJkeYwWXjUnllTRHJcdH85vqJnDUskd+/k8/vFm/BOYgIM8ZnxFPX2MTt52Rz/ojBxMdEHl3fzGhsctQ3NnH2/e9QdrCOMIPLx6fx8upCzODlO89meHJ/auoajwbTwdoGLn/wQ3buq2bR986lT2Q4qfF9KD1Yy8HDDQxPjqWhsemY//bbSg/yyAfb+MGMEQzqHw00B+bLawr5yllDiYk6dk/u20+v5OXVhcT1iWDFjy+huq6RJVvLePyjHfzHVWMYmRIHQGOTIzzMOFBdx78+v4Zx6fF8+6LhNDY51hdWMCYtnp+8tI78koNMHTqQQbHR3JCTyZbiKgxjbHpcq3sC5YfquOF/l7C7vJqYqHAOVNczY0wyd80axQW/fg+A288Zyr9cOoI+keEcrm9kys/fpvJwAzdNyeS/rhlPSeVhdpZXs3TrPh5+fyuH6hq5e9bIY36fvwgd0xDpJvJLDjLzdx/Q5BwRYWF8dNcFFOyvYdGGYqprG8jduZ8dZYcYmRqH0Xwtyq1nZlFRU88tf/qEipp6wgxGpcYxsF8Uk08ZwJfPyuJ7z6zijKEDGdQvmsT+UVw0KpmmJsfvFuexdOs+zjo1ke9efBo1dY1U1NSzsaiSbz61gsP1zWfIR0eE8T+3TOLUwf3Zs7+G+97Y1PztiqMGs73sEFtLD5EcF01xZS1Xn57O9y4+jfvf2MSu8mpq6hvJLzkIwLCkfpQdrCM+JpLZ41N54uMdTMtO5J1NJdx/7TjufmEtTQ4mZCawrfQgVYcbiAgzwsOMv3xtKg8uzmPT3ir2HawlMjyMUxL7sqX4IOPS49mx7xB1DU3cMvUUnvpkJ/deOYYbz8iksqaBG/53CZuLqzgzO5F7Lh9F5sC+fPn/LWPlrgOMTo1jfEY8y3eUMyypP/ddO55zf/ku8TGR7DlQQ1ZiX3bsqz76Hp2RNYAF887k3/6+lgXLdzOwbxSO5n/cAa6amMaaPRVsKz3E2PQ41u2pJC2+D4UVzV9ffOS/E0BSbDQTMhL4xTVjue2JXOZMTONr52QDcLi+kfvf2MTra/eyv7qOnKwBrNp1gDOHDeLdzSVcNHIw72wqISdrAJ/uOkBDYxM/mT2agf2j+eenV5Kd1I+SylruuGAYf3gnn2rv+qWZY1L48vQspmQNPDrN9UUpNES6kfe3lPLBllJGpsRyfQvHKU5kS3EVv35zM1+ZPpQzh7V/SmXV7gN8sKWUjAExXDQqmfiYz6bHyg/V8eqaQq7PycQ5+O3bW9hWeohrJqUza2zKMX89NzY5Ptm2jxU797O64ADxMVF8vLWMoorDDOofTdnBWsalx7PwzunM+/MKFm0o5t4rRnPOaUm8sW4vh2obeGb5bg7U1GPAJaOTuXRMMmsLKnn8H9uPBkzGgL7UNjSyrfQQA/pGUlFTT3xMJPur6wG4eeoQ/vpJ87RcVHgYdY1N3DJ1CO9tLuVwfSOnJceyfEc5keHNe22/v+l0fvj8apqa4BvnDyNjQAy1DU38+O/ryE7qx7bSQ1x9ejp9IsOpqKnjn6adwlOf7GLRhmLGpMUxLj2eJ5fsZOrQgfz19mkAfJBXyk9fWs+ssSlkDerH8h3lvPDpnqOhEh5mPHTLJNIHxPCbt7YcDYfbzs7mzGGJ1DY0Unjg8NE9jK9Mz+Lq09P57oJVhIUZhQdqSIiJJCzM+M31E/jSI0sBmH5qIl87J5tB/aIZlxHf7t8NhYaIdKmyg7Ws2Lmfc4cn8eu3NjN7fCqnDxnAip37+cFzq3n69mmkxH92EPyNdXu546kV/GT2aL48fSgAFdX1PLdiNzdPHUKTgz4RYZQfquOj/DIuHZPCL17bSENjE0MH9WdsehznDE9ixc5ySipreX3dXmIiw7nv2nHHBNzH+WW8vKaQjAF9+fq52XyUX8bAflGMz0gAmqckf/bqBjYUVnLByMF8/dzsz00vBR6oXrX7ANlJ/Yhr4XjUEXe/sIanl+3m0tHJrC+sZE/Al4394upx3Dx1yOfWeXP9XpJio5k05LPjFbvLq7n4gffpFx3Bn2+bwpi0ePJLqugTGU56QkyHHhBXaIhIt3dkzyHUVNTU8/D7W/nK9CzCzVixcz8NTY5RqXEMHdSv9Q0EWLenggH9okhPiOmkbpspNEREJGjBhoa+I1xERIKm0BARkaApNEREJGgKDRERCZpCQ0REgqbQEBGRoCk0REQkaAoNEREJWshd3GdmpcDONq4+CCjrwHZ6gt44Zuid49aYe4e2jvkU51xSawuFXGi0h5nlBnNFZCjpjWOG3jlujbl36Owxa3pKRESCptAQEZGgKTSO9YjfDfigN44Zeue4NebeoVPHrGMaIiISNO1piIhI0BQaHjObaWabzSzfzO7yu5/OYmY7zGytma0ys1yvNtDMFplZnnc/oLXtdGdm9riZlZjZuoBai2O0Zg967/saM5vkX+dtd4Ix32tme7z3epWZXRbw2t3emDeb2Qx/um4fM8s0s3fNbKOZrTez73j1kH2vTzLmrnuvnXO9/gaEA1uBbCAKWA2M9ruvThrrDmDQcbVfAnd5j+8C7ve7z3aO8VxgErCutTEClwGvAwZMAz7xu/8OHPO9wA9aWHa09zseDQz1fvfD/R5DG8acCkzyHscCW7yxhex7fZIxd9l7rT2NZlOAfOfcNudcHbAAmONzT11pDjDfezwfuMrHXtrNOfcBUH5c+URjnAM86ZotBRLMLLVrOu04JxjzicwBFjjnap1z24F8mv8f6FGcc0XOuU+9x1XARiCdEH6vTzLmE+nw91qh0Swd2B3wvICTvxE9mQPeMrMVZjbPqyU754qg+ZcSGOxbd53nRGMM9ff+Tm8q5vGAaceQG7OZZQGnA5/QS97r48YMXfReKzSaWQu1UD2tbLpzbhIwC/iWmZ3rd0M+C+X3/iFgGDARKAJ+49VDasxm1h/4G/Bd51zlyRZtodYjx93CmLvsvVZoNCsAMgOeZwCFPvXSqZxzhd59CfAizbuqxUd20737Ev867DQnGmPIvvfOuWLnXKNzrgl4lM+mJUJmzGYWSfM/nk85517wyiH9Xrc05q58rxUazZYDw81sqJlFATcCC33uqcOZWT8ziz3yGLgUWEfzWOd6i80FXvKnw051ojEuBG71zqyZBlQcmdro6Y6br7+a5vcamsd8o5lFm9lQYDiwrKv7ay8zM+AxYKNz7oGAl0L2vT7RmLv0vfb7bIDucqP5zIotNJ9dcI/f/XTSGLNpPpNiNbD+yDiBRGAxkOfdD/S713aO82mad9Hraf5L67YTjZHm3fc/eu/7WiDH7/47cMx/9sa0xvvHIzVg+Xu8MW8GZvndfxvHfDbNUy1rgFXe7bJQfq9PMuYue691RbiIiARN01MiIhI0hYaIiARNoSEiIkFTaIiISNAUGiIiEjSFhoiIBE2hISIiQVNoiIhI0P4/e82oZJd+J4YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = pickle.load(open('./model/housing_train_losses.pickle', \"rb\"))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f90677b588>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_losses = pickle.load(open('./model/housing_val_losses.pickle', \"rb\"))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the final step, we define a function to compute the MAE and print the corresponding results for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(data_num, data_cat, data_resp):\n",
    "    with torch.no_grad():\n",
    "        errors = []\n",
    "        for k, (mb_Xn, mb_Xc, mb_Y) in enumerate(get_batch(data_num, data_cat, data_resp, mb_size, True)):\n",
    "            Xn = torch.from_numpy(mb_Xn).cuda() if gpu_available else torch.from_numpy(mb_Xn)\n",
    "            Xc = [torch.from_numpy(mb_Xc[:,i]).long().cuda() if gpu_available else torch.from_numpy(mb_Xc[:,i]).long() for i in range(len(categorical_vars))]\n",
    "            actual = torch.from_numpy(mb_Y).cuda() if gpu_available else torch.from_numpy(mb_Y)\n",
    "            predicted = model(Xc, Xn)\n",
    "            actual = actual.cpu().numpy().flatten()\n",
    "            predicted = predicted.cpu().numpy().flatten()\n",
    "            errors.append(np.abs(actual - predicted))\n",
    "        return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Train): 6902.461426\n",
      "MAE (Validation): 17743.656250\n",
      "MAE (Test): 21025.816406\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model/housing_model_state_dict.pt', map_location='cpu'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"MAE (Train): %f\" % MAE(df_housing_num_train, df_housing_cat_train, df_housing_resp_train))\n",
    "print(\"MAE (Validation): %f\" % MAE(df_housing_num_val, df_housing_cat_val, df_housing_resp_val))\n",
    "print(\"MAE (Test): %f\" % MAE(df_housing_num_test, df_housing_cat_test, df_housing_resp_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
