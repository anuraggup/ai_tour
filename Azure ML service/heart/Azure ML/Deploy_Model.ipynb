{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Trained Model\n",
    "### Deploy a trained model with Azure ML service to be consumed as a web service\n",
    "#### <font color='red'> Before you begin: please download the dataset and save it into the \"data\" folder as \"heart.csv\". You will need to login into Kaggle to be able to download the dataset. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup diagnostics collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\AI+ Tour Tutorials\\Azure ML service\\heart\\Azure ML\\aml_config\\config.json\n",
      "Workspace name: ML-Service-Workspace\n",
      "Azure region: eastus\n",
      "Resource group: ML-Service-RG\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace name: \" + ws.name, \n",
    "      \"Azure region: \" + ws.location,\n",
    "      \"Resource group: \" + ws.resource_group, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register the model in the Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model lr_model.pickle\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"../model/lr_model.pickle\",\n",
    "                       model_name = \"lr_model.pickle\",\n",
    "                       tags = {'area': \"heart diseases\", 'type': \"classification\", 'version': \"1.0\"},\n",
    "                       description = \"logistic regression model to predict heart disease\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you need to list the models already deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lr_model.pickle \tVersion: 1 \tDescription: logistic regression model to predict heart disease {'area': 'heart diseases', 'type': 'classification', 'version': '1.0'}\n"
     ]
    }
   ],
   "source": [
    "models = Model.list(workspace=ws, tags=['area'])\n",
    "for m in models:\n",
    "    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the score.py script, to be used for model scoring in the container image to be deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # note here \"lr_model.pickle\" is the name of the model registered under\n",
    "    model_path = Model.get_model_path(\"lr_model.pickle\")\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)[\"data\"]\n",
    "        data = numpy.array(data)\n",
    "        result = model.predict(data)\n",
    "        # you can return any datatype as long as it is JSON-serializable\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the YAML file with the Conda dependencies for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                                  execution_script=\"score.py\",\n",
    "                                                  conda_file=\"myenv.yml\",\n",
    "                                                  tags = {'area': \"heart diseases\", 'type': \"classification\"},\n",
    "                                                  description = \"Image with the classification model to predict heart disease\")\n",
    "\n",
    "image = Image.create(name = \"image1\",\n",
    "                     # this is the model object. note you can pass in 0-n models via this list-type parameter\n",
    "                     # in case you need to reference multiple models, or none at all, in your scoring script.\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.................................\n",
      "SucceededImage creation operation finished for image image1:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you need to list existing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1(v.1 [Succeeded]) stored at mlservicacrobkxduqv.azurecr.io/image1:1 with build log https://mlservicstoragevqkhmalr.blob.core.windows.net/azureml/ImageLogs/66c203f1-1eda-4c18-a25d-f884634a83f2/build.log?sv=2017-04-17&sr=b&sig=iIUq9dET5iKGQRn037oQU5G4ck5kc%2BREHhUGtD1yrWg%3D&st=2019-02-14T18%3A51%3A05Z&se=2019-03-16T18%3A56%3A05Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "for i in Image.list(workspace = ws,tags = [\"area\"]):\n",
    "    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a configuration object for image deployment on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'area': \"heart diseases\", 'type': \"classification\"}, \n",
    "                                               description = \"Image with the classification model to predict heart disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy image as web service on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aci-service2\n",
      "Creating service\n",
      "Running................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = \"aci-service2\"\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test web service consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 77.05%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "df_heart = pd.read_csv(\"../data/heart.csv\")\n",
    "\n",
    "df_heart_X = df_heart.drop([\"target\"], axis=1).values\n",
    "df_heart_y = df_heart[\"target\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_heart_X, df_heart_y, test_size = 0.2, random_state=123)\n",
    "\n",
    "test_sample = json.dumps({'data': X_test.tolist()})\n",
    "test_sample = bytes(test_sample, encoding = 'utf8')\n",
    "\n",
    "y_test_pred = aci_service.run(input_data=test_sample)\n",
    "print(\"Test Accuracy {:.2f}%\".format(sum(y_test_pred == y_test) / len(y_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azure_automl)",
   "language": "python",
   "name": "azure_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
