{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Trained Model from Automated ML\n",
    "### Deploy the best trained model from an Automated ML job to be consumed as a web service\n",
    "\n",
    "#### <font color='red'> Before you begin: please download the dataset from Kaggle and save it into the \"data\" folder as \"heart.csv\". You will need to login into Kaggle to be able to download the dataset. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup diagnostics collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\AI+ Tour Tutorials\\Azure ML service\\heart\\Azure ML\\aml_config\\config.json\n",
      "Workspace name: ML-Service-Workspace\n",
      "Azure region: eastus\n",
      "Resource group: ML-Service-RG\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace name: \" + ws.name, \n",
    "      \"Azure region: \" + ws.location, \n",
    "      \"Resource group: \" + ws.resource_group, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register the model in the Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model automl_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"best_model.joblib\",\n",
    "                       model_name = \"automl_model.joblib\",\n",
    "                       tags = {'area': \"heart diseases\", 'type': \"classification\", 'version': \"1.0\"},\n",
    "                       description = \"automl model to predict heart disease\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you need to list the models already deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: automl_model.joblib \tVersion: 1 \tDescription: automl model to predict heart disease {'area': 'heart diseases', 'type': 'classification', 'version': '1.0'}\n",
      "Name: lr_model.pickle \tVersion: 1 \tDescription: logistic regression model to predict heart disease {'area': 'heart diseases', 'type': 'classification', 'version': '1.0'}\n"
     ]
    }
   ],
   "source": [
    "models = Model.list(workspace=ws, tags=['area'])\n",
    "for m in models:\n",
    "    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the score.py script, to be used for model scoring in the container image to be deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score_automl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score_automl.py\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "import azureml.train.automl\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # note here \"lr_model.pickle\" is the name of the model registered under\n",
    "    model_path = Model.get_model_path(\"automl_model.joblib\")\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)[\"data\"]\n",
    "        data = numpy.array(data)\n",
    "        result = model.predict(data)\n",
    "        # you can return any datatype as long as it is JSON-serializable\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the YAML file with the Conda dependencies for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn'], pip_packages=['azureml-sdk[automl]', 'joblib'])\n",
    "\n",
    "with open(\"myenv_automl.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                                  execution_script=\"score_automl.py\",\n",
    "                                                  conda_file=\"myenv_automl.yml\",\n",
    "                                                  tags = {'area': \"heart diseases\", 'type': \"classification\"},\n",
    "                                                  description = \"Image with the classification model to predict heart disease\")\n",
    "\n",
    "image = Image.create(name = \"imageaml\",\n",
    "                     # this is the model object. note you can pass in 0-n models via this list-type parameter\n",
    "                     # in case you need to reference multiple models, or none at all, in your scoring script.\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.....................................................\n",
      "SucceededImage creation operation finished for image imageaml:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you need to list existing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imageaml(v.1 [Succeeded]) stored at mlservicacrobkxduqv.azurecr.io/imageaml:1 with build log https://mlservicstoragevqkhmalr.blob.core.windows.net/azureml/ImageLogs/d83a1799-e675-4ac6-842c-bc087c054f0d/build.log?sv=2017-04-17&sr=b&sig=CicMtbSQLzGISRkj94k1X1FBcVviGJUhtEeQI6pbclY%3D&st=2019-02-14T21%3A00%3A00Z&se=2019-03-16T21%3A05%3A00Z&sp=rl\n",
      "image1(v.1 [Succeeded]) stored at mlservicacrobkxduqv.azurecr.io/image1:1 with build log https://mlservicstoragevqkhmalr.blob.core.windows.net/azureml/ImageLogs/66c203f1-1eda-4c18-a25d-f884634a83f2/build.log?sv=2017-04-17&sr=b&sig=iIUq9dET5iKGQRn037oQU5G4ck5kc%2BREHhUGtD1yrWg%3D&st=2019-02-14T18%3A51%3A05Z&se=2019-03-16T18%3A56%3A05Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "for i in Image.list(workspace = ws,tags = [\"area\"]):\n",
    "    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a configuration object for image deployment on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'area': \"heart diseases\", 'type': \"classification\"}, \n",
    "                                               description = \"Image with the classification model to predict heart disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy image as web service on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aci-automl\n",
      "Creating service\n",
      "Running......................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = \"aci-automl\"\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the logs from the service deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-14T21:12:09,442473845+00:00 - rsyslog/run \n",
      "2019-02-14T21:12:09,444685257+00:00 - gunicorn/run \n",
      "ok: run: rsyslog: (pid 14) 0s\n",
      "2019-02-14T21:12:09,447882318+00:00 - nginx/run \n",
      "2019-02-14T21:12:09,448577153+00:00 - iot-server/run \n",
      "ok: run: rsyslog: (pid 14) 0s\n",
      "ok: run: gunicorn: (pid 15) 0s\n",
      "ok: run: nginx: (pid 13) 0s\n",
      "ok: run: rsyslog: (pid 14) 0s\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2019-02-14T21:12:09,594289814+00:00 - iot-server/finish 1 0\n",
      "2019-02-14T21:12:09,595630781+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "{\"timestamp\": \"2019-02-14T21:12:09.864137Z\", \"message\": \"Starting gunicorn 19.6.0\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Starting gunicorn %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:09.864879Z\", \"message\": \"Listening at: http://127.0.0.1:9090 (15)\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Listening at: %s (%s)\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:09.864964Z\", \"message\": \"Using worker: sync\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Using worker: %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:09.865899Z\", \"message\": \"worker timeout is set to 300\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:09.867030Z\", \"message\": \"Booting worker with pid: 42\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Booting worker with pid: %s\", \"stack_info\": null}\n",
      "Initializing logger\n",
      "{\"timestamp\": \"2019-02-14T21:12:16.718896Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insights client\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:16.720213Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up request id generator\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:16.720409Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insight hooks\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:16.720582Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Invoking user's init function\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "2019-02-14 21:12:16,723 | azureml.core.run | DEBUG | Could not load run context Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run., switching offline: False\n",
      "2019-02-14 21:12:16,723 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-02-14 21:12:16,723 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n",
      "2019-02-14 21:12:16,723 | azureml.core.model | DEBUG | version is None. Latest version is 1\n",
      "2019-02-14 21:12:16,723 | azureml.core.model | DEBUG | Found model path at azureml-models/automl_model.joblib/1/best_model.joblib\n",
      "{\"timestamp\": \"2019-02-14T21:12:16.728622Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Users's init has completed successfully\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:16.728956Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Scoring timeout setting is not found. Use default timeout: 3600000 ms\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:18.896652Z\", \"message\": \"127.0.0.1 - - [14/Feb/2019:21:12:18 +0000] \\\"GET / HTTP/1.0\\\" 200 7 \\\"-\\\" \\\"Go-http-client/1.1\\\"\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.access\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-02-14T21:12:33.930019Z\", \"message\": \"127.0.0.1 - - [14/Feb/2019:21:12:33 +0000] \\\"GET / HTTP/1.0\\\" 200 7 \\\"-\\\" \\\"Go-http-client/1.1\\\"\", \"host\": \"wk-caas-c996b8f584aa40fbb2b6c02765430474-d72b36648f880a45ead09a\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.access\", \"stack_info\": null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test web service consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 81.97%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "df_heart = pd.read_csv(\"../data/heart.csv\")\n",
    "\n",
    "df_heart_X = df_heart.drop([\"target\"], axis=1).values\n",
    "df_heart_y = df_heart[\"target\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_heart_X, df_heart_y, test_size = 0.2, random_state=123)\n",
    "\n",
    "test_sample = json.dumps({'data': X_test.tolist()})\n",
    "test_sample = bytes(test_sample, encoding = 'utf8')\n",
    "\n",
    "y_test_pred = aci_service.run(input_data=test_sample)\n",
    "print(\"Test Accuracy {:.2f}%\".format(sum(y_test_pred == y_test) / len(y_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azure_automl)",
   "language": "python",
   "name": "azure_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
